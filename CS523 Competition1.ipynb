{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b52dcf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ib_insync in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (0.9.86)\n",
      "Requirement already satisfied: eventkit in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ib_insync) (1.0.3)\n",
      "Requirement already satisfied: nest-asyncio in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from ib_insync) (1.5.6)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from eventkit->ib_insync) (1.22.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ib_insync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3d0e77e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Interactive Brokers\n"
     ]
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "\n",
    "# Utilize an instance of IB\n",
    "ib = IB()\n",
    "\n",
    "# Connect to the IB server using await in front of the connectAsync method\n",
    "try:\n",
    "    await ib.connectAsync('127.0.0.1', 7497, clientId=1)\n",
    "    print(\"Connected to Interactive Brokers\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Runtime Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "# from ib_insync import *\n",
    "\n",
    "# ib = IB()\n",
    "# ib.connect('127.0.0.1', 7497, clientId=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16b32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = Future('ES', '202406', 'CME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f5088c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Future(conId=551601561, symbol='ES', lastTradeDateOrContractMonth='20240621', multiplier='50', exchange='CME', currency='USD', localSymbol='ESM4', tradingClass='ES')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await ib.qualifyContractsAsync(contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12b14ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ib.reqMarketDataType(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f7d38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BarData(date=datetime.datetime(2024, 2, 15, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5077.5, high=5088.75, low=5077.0, close=5081.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 15, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5081.25, high=5090.75, low=5077.75, close=5082.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 15, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5082.75, high=5086.25, low=5072.5, close=5082.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 15, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5082.75, high=5090.75, low=5081.5, close=5085.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 15, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5085.5, high=5102.0, low=5084.5, close=5099.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 15, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5099.0, high=5107.5, low=5095.25, close=5103.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 15, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5103.75, high=5106.5, low=5097.0, close=5105.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 15, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5105.75, high=5110.75, low=5104.75, close=5109.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 16, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5102.0, high=5104.25, low=5077.75, close=5083.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 16, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5083.25, high=5096.5, low=5072.0, close=5094.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 16, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5094.0, high=5109.75, low=5093.75, close=5107.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 16, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5107.25, high=5108.75, low=5101.75, close=5103.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 16, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5103.5, high=5108.75, low=5092.25, close=5108.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 16, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5108.75, high=5113.75, low=5084.0, close=5090.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 16, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5090.5, high=5092.25, low=5074.5, close=5079.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 16, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5079.5, high=5080.0, low=5072.0, close=5073.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 20, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5060.25, high=5067.25, low=5044.5, close=5049.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 20, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5049.75, high=5053.25, low=5040.5, close=5053.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 20, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5053.0, high=5056.0, low=5039.5, close=5040.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 20, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5040.0, high=5040.5, low=5027.25, close=5037.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 20, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5037.25, high=5042.5, low=5030.0, close=5041.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 20, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5041.75, high=5051.0, low=5034.75, close=5050.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 20, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5050.25, high=5051.75, low=5033.75, close=5050.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 20, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5050.75, high=5051.25, low=5045.0, close=5048.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 21, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5036.25, high=5039.25, low=5031.25, close=5034.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 21, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5034.75, high=5042.75, low=5032.5, close=5035.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 21, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5035.0, high=5045.25, low=5034.75, close=5042.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 21, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5042.0, high=5042.75, low=5028.25, close=5038.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 21, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5038.0, high=5039.75, low=5026.25, close=5035.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 21, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5035.75, high=5043.5, low=5021.25, close=5028.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 21, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5028.0, high=5056.75, low=5017.5, close=5054.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 21, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5054.25, high=5079.5, low=5031.75, close=5078.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 22, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5122.25, high=5136.5, low=5112.0, close=5131.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 22, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5131.0, high=5139.5, low=5127.75, close=5130.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 22, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5130.0, high=5141.75, low=5127.75, close=5135.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 22, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5135.25, high=5148.0, low=5131.75, close=5147.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 22, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5147.75, high=5156.0, low=5143.5, close=5156.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 22, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5156.0, high=5168.5, low=5152.5, close=5155.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 22, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5155.75, high=5166.75, low=5154.5, close=5158.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 22, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5158.25, high=5158.25, low=5152.75, close=5154.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 23, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5175.75, high=5184.5, low=5174.0, close=5180.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 23, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5180.5, high=5182.5, low=5167.0, close=5170.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 23, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5170.0, high=5171.0, low=5153.5, close=5167.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 23, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5167.5, high=5172.75, low=5160.5, close=5169.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 23, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5169.0, high=5173.25, low=5166.0, close=5168.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 23, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5168.0, high=5168.75, low=5158.75, close=5166.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 23, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5166.0, high=5170.25, low=5159.75, close=5160.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 23, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5160.75, high=5161.0, low=5155.5, close=5156.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 26, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5164.75, high=5169.25, low=5159.0, close=5162.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 26, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5162.5, high=5167.0, low=5155.5, close=5156.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 26, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5156.5, high=5160.5, low=5151.75, close=5158.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 26, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5158.75, high=5160.75, low=5153.0, close=5154.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 26, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5154.75, high=5157.75, low=5141.75, close=5150.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 26, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5150.25, high=5155.5, low=5146.5, close=5149.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 26, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5149.0, high=5154.75, low=5139.75, close=5141.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 26, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5141.25, high=5141.5, low=5137.25, close=5138.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 27, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5147.5, high=5148.0, low=5135.75, close=5140.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 27, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5140.0, high=5146.5, low=5136.25, close=5141.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 27, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5141.75, high=5142.25, low=5135.0, close=5139.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 27, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5139.5, high=5140.5, low=5130.25, close=5131.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 27, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5131.0, high=5139.25, low=5127.75, close=5138.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 27, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5138.25, high=5147.5, low=5137.75, close=5147.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 27, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5147.0, high=5152.5, low=5142.75, close=5149.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 27, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5149.75, high=5153.75, low=5148.75, close=5151.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 28, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5133.0, high=5138.25, low=5129.0, close=5133.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 28, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5133.0, high=5145.25, low=5131.75, close=5144.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 28, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5144.75, high=5148.75, low=5141.5, close=5146.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 28, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5146.0, high=5147.0, low=5134.25, close=5138.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 28, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5138.75, high=5148.0, low=5134.75, close=5146.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 28, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5146.5, high=5147.25, low=5131.5, close=5138.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 28, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5138.75, high=5143.25, low=5133.5, close=5142.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 28, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5142.75, high=5143.0, low=5127.75, close=5130.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 29, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5159.0, high=5166.75, low=5158.75, close=5163.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 29, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5163.25, high=5165.75, low=5145.75, close=5152.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 29, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5152.25, high=5155.25, low=5130.75, close=5144.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 29, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5144.25, high=5152.5, low=5142.75, close=5151.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 29, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5151.75, high=5157.5, low=5151.5, close=5156.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 29, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5156.5, high=5161.5, low=5149.75, close=5155.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 29, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5155.75, high=5176.0, low=5154.75, close=5158.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 2, 29, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5158.0, high=5164.75, low=5154.75, close=5162.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 1, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5167.0, high=5173.0, low=5162.5, close=5168.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 1, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5168.25, high=5186.0, low=5163.75, close=5184.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 1, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5184.25, high=5191.75, low=5179.0, close=5189.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 1, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5189.25, high=5198.75, low=5184.75, close=5196.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 1, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5196.25, high=5205.25, low=5194.5, close=5204.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 1, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5204.5, high=5211.25, low=5203.5, close=5209.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 1, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5209.25, high=5209.75, low=5201.25, close=5207.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 1, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5207.0, high=5207.25, low=5200.25, close=5200.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 4, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5197.75, high=5203.75, low=5197.25, close=5202.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 4, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5202.5, high=5206.5, low=5198.0, close=5204.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 4, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5204.25, high=5206.25, low=5199.25, close=5205.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 4, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5205.25, high=5209.75, low=5202.5, close=5207.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 4, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5207.5, high=5208.75, low=5201.0, close=5205.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 4, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5205.75, high=5219.5, low=5203.75, close=5216.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 4, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5216.25, high=5220.0, low=5199.5, close=5200.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 4, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5200.25, high=5201.0, low=5195.25, close=5196.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 5, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5179.25, high=5180.25, low=5169.75, close=5172.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 5, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5172.5, high=5184.0, low=5150.75, close=5157.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 5, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5157.25, high=5160.0, low=5145.25, close=5152.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 5, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5152.5, high=5161.25, low=5151.0, close=5156.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 5, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5156.0, high=5157.5, low=5142.25, close=5143.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 5, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5143.25, high=5149.5, low=5131.0, close=5132.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 5, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5132.75, high=5149.75, low=5124.25, close=5147.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 5, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5147.25, high=5154.25, low=5146.75, close=5152.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 6, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5181.25, high=5184.25, low=5172.0, close=5174.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 6, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5174.75, high=5181.5, low=5159.25, close=5180.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 6, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5180.0, high=5192.25, low=5180.0, close=5188.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 6, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5188.0, high=5196.5, low=5186.25, close=5189.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 6, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5189.25, high=5195.5, low=5166.5, close=5177.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 6, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5177.0, high=5180.0, low=5160.5, close=5168.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 6, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5168.0, high=5178.75, low=5161.0, close=5174.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 6, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5174.0, high=5178.0, low=5172.75, close=5175.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 7, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5205.5, high=5210.5, low=5195.75, close=5208.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 7, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5208.25, high=5223.25, low=5203.75, close=5218.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 7, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5218.25, high=5222.25, low=5212.0, close=5221.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 7, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5221.0, high=5224.5, low=5214.75, close=5220.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 7, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5220.25, high=5233.75, low=5216.75, close=5231.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 7, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5231.75, high=5233.5, low=5222.0, close=5223.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 7, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5223.75, high=5231.0, low=5215.0, close=5222.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 7, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5222.75, high=5223.25, low=5206.75, close=5220.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 8, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5229.0, high=5253.0, low=5227.0, close=5252.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 8, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5252.5, high=5257.5, low=5244.25, close=5250.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 8, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5250.25, high=5251.25, low=5213.25, close=5214.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 8, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5214.5, high=5223.5, low=5196.75, close=5199.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 8, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5199.5, high=5206.75, low=5185.0, close=5190.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 8, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5190.75, high=5218.75, low=5189.75, close=5212.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 8, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5212.75, high=5218.25, low=5191.25, close=5192.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 8, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5192.25, high=5200.75, low=5190.75, close=5195.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 11, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5177.75, high=5182.5, low=5166.5, close=5166.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 11, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5166.75, high=5179.0, low=5157.0, close=5177.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 11, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5177.75, high=5181.0, low=5163.25, close=5180.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 11, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5180.5, high=5184.0, low=5171.5, close=5182.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 11, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5182.25, high=5188.0, low=5174.0, close=5183.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 11, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5183.0, high=5191.5, low=5179.25, close=5188.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 11, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5188.75, high=5189.0, low=5177.25, close=5185.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 11, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5185.75, high=5192.0, low=5183.75, close=5191.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 12, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5206.25, high=5210.0, low=5179.75, close=5206.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 12, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5206.25, high=5237.75, low=5201.5, close=5232.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 12, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5232.25, high=5238.5, low=5224.25, close=5231.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 12, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5231.75, high=5232.75, low=5207.5, close=5216.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 12, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5216.5, high=5231.25, low=5208.25, close=5229.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 12, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5229.0, high=5243.0, low=5227.75, close=5240.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 12, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5240.5, high=5247.0, low=5237.0, close=5241.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 12, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5241.5, high=5244.25, low=5238.75, close=5239.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 13, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5243.5, high=5243.5, low=5231.25, close=5233.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 13, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5233.0, high=5240.0, low=5228.5, close=5234.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 13, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5234.0, high=5239.25, low=5230.5, close=5236.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 13, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5236.5, high=5239.5, low=5233.0, close=5237.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 13, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5237.25, high=5246.0, low=5236.25, close=5244.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 13, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5244.0, high=5245.0, low=5236.75, close=5238.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 13, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5238.0, high=5240.25, low=5217.25, close=5233.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 13, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5233.25, high=5238.75, low=5231.5, close=5237.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 14, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5240.0, high=5241.5, low=5208.75, close=5209.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 14, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5209.5, high=5226.0, low=5203.0, close=5216.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 14, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5216.25, high=5224.0, low=5210.25, close=5220.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 14, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5220.0, high=5221.75, low=5208.0, close=5208.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 14, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5208.75, high=5216.0, low=5196.75, close=5215.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 14, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5215.25, high=5222.25, low=5208.25, close=5209.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 14, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5209.0, high=5220.5, low=5188.0, close=5220.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 14, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5220.25, high=5222.0, low=5216.5, close=5218.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 15, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5186.25, high=5198.25, low=5180.25, close=5182.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 15, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5182.5, high=5201.75, low=5172.75, close=5195.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 15, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5195.75, high=5196.75, low=5179.75, close=5181.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 15, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5181.5, high=5183.5, low=5167.75, close=5169.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 15, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5169.0, high=5184.5, low=5168.5, close=5184.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 15, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5184.0, high=5190.5, low=5176.25, close=5186.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 15, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5186.75, high=5190.75, low=5177.5, close=5183.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 15, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5183.0, high=5187.5, low=5181.0, close=5183.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 18, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5225.75, high=5233.75, low=5222.5, close=5223.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 18, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5223.75, high=5240.25, low=5223.0, close=5237.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 18, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5237.0, high=5237.75, low=5224.0, close=5227.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 18, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5227.5, high=5230.5, low=5219.5, close=5220.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 18, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5220.25, high=5227.5, low=5217.75, close=5223.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 18, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5223.0, high=5229.0, low=5216.75, close=5222.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 18, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5222.75, high=5226.5, low=5210.0, close=5215.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 18, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5215.25, high=5217.0, low=5210.5, close=5214.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 19, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5205.75, high=5206.25, low=5195.0, close=5200.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 19, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5200.75, high=5210.0, low=5195.5, close=5206.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 19, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5206.0, high=5218.5, low=5205.25, close=5215.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 19, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5215.75, high=5235.75, low=5213.75, close=5231.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 19, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5231.25, high=5239.0, low=5227.75, close=5234.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 19, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5234.25, high=5237.75, low=5229.0, close=5233.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 19, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5233.0, high=5244.75, low=5226.25, close=5242.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 19, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5242.5, high=5244.0, low=5238.75, close=5239.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 20, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5241.0, high=5243.5, low=5235.25, close=5237.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 20, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5237.75, high=5248.0, low=5236.5, close=5242.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 20, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5242.0, high=5246.5, low=5238.5, close=5242.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 20, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5242.0, high=5244.5, low=5236.5, close=5244.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 20, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5244.25, high=5244.25, low=5233.0, close=5237.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 20, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5237.25, high=5278.75, low=5236.75, close=5272.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 20, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5272.5, high=5289.75, low=5271.25, close=5287.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 20, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5287.75, high=5297.75, low=5285.0, close=5296.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 21, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5315.0, high=5321.5, low=5308.5, close=5315.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 21, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5315.5, high=5321.5, low=5312.75, close=5317.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 21, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5317.5, high=5320.75, low=5311.5, close=5319.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 21, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5319.0, high=5322.75, low=5315.5, close=5319.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 21, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5319.0, high=5319.25, low=5308.5, close=5309.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 21, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5309.5, high=5312.5, low=5301.5, close=5304.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 21, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5304.5, high=5312.75, low=5300.0, close=5302.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 21, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5302.75, high=5309.25, low=5301.25, close=5307.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 22, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5301.25, high=5304.75, low=5294.0, close=5297.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 22, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5297.75, high=5303.25, low=5289.75, close=5290.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 22, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5290.25, high=5298.25, low=5289.75, close=5296.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 22, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5296.75, high=5299.0, low=5289.25, close=5298.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 22, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5298.25, high=5306.0, low=5297.25, close=5305.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 22, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5305.5, high=5306.0, low=5299.25, close=5301.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 22, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5301.75, high=5303.0, low=5291.0, close=5292.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 22, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5292.0, high=5293.75, low=5287.75, close=5289.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 25, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5276.75, high=5282.75, low=5274.25, close=5281.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 25, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5281.5, high=5287.75, low=5278.75, close=5285.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 25, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5285.0, high=5287.5, low=5282.25, close=5284.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 25, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5284.75, high=5286.0, low=5281.0, close=5283.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 25, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5283.25, high=5286.25, low=5279.75, close=5285.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 25, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5285.75, high=5288.75, low=5284.5, close=5287.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 25, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5287.25, high=5287.5, low=5275.75, close=5277.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 25, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5277.25, high=5281.0, low=5277.0, close=5280.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 26, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5290.0, high=5292.5, low=5286.25, close=5290.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 26, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5290.25, high=5294.25, low=5284.5, close=5291.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 26, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5291.25, high=5293.0, low=5288.75, close=5292.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 26, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5292.25, high=5293.0, low=5285.5, close=5287.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 26, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5287.25, high=5288.5, low=5283.0, close=5285.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 26, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5285.0, high=5289.0, low=5284.5, close=5287.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 26, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5287.0, high=5287.75, low=5263.0, close=5266.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 26, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5266.25, high=5274.0, low=5264.75, close=5272.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 27, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5293.25, high=5294.0, low=5283.0, close=5284.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 27, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5284.75, high=5285.5, low=5271.75, close=5274.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 27, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5274.25, high=5277.25, low=5270.75, close=5271.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 27, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5271.5, high=5281.0, low=5270.5, close=5279.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 27, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5279.5, high=5281.5, low=5273.5, close=5278.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 27, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5278.5, high=5287.0, low=5276.75, close=5280.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 27, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5280.0, high=5310.5, low=5275.75, close=5310.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 27, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5310.25, high=5314.0, low=5307.75, close=5308.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 28, 8, 30, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5309.75, high=5314.5, low=5305.0, close=5310.0, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 28, 9, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5310.0, high=5315.0, low=5307.0, close=5312.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 28, 10, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5312.5, high=5316.25, low=5309.75, close=5314.75, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 28, 11, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5314.75, high=5314.75, low=5307.5, close=5310.25, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 28, 12, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5310.25, high=5311.0, low=5305.0, close=5309.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 28, 13, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5309.5, high=5318.0, low=5305.25, close=5316.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 28, 14, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5316.5, high=5321.0, low=5303.25, close=5305.5, volume=-1.0, average=-1.0, barCount=-1)\n",
      "BarData(date=datetime.datetime(2024, 3, 28, 15, 0, tzinfo=zoneinfo.ZoneInfo(key='US/Central')), open=5305.5, high=5308.25, low=5302.0, close=5304.25, volume=-1.0, average=-1.0, barCount=-1)\n"
     ]
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "\n",
    "# Assume 'ib' is already connected and is an instance of ib_insync.IB()\n",
    "# Also assume 'contract' has been created and is a valid ib_insync.Contract object\n",
    "\n",
    "# Use the asynchronous version of the method with await\n",
    "try:\n",
    "    historical_data = await ib.reqHistoricalDataAsync(\n",
    "        contract, endDateTime='', durationStr='30 D',\n",
    "        barSizeSetting='1 hour', whatToShow='MIDPOINT', useRTH=True\n",
    "    )\n",
    "    \n",
    "    # Proceed with the historical data\n",
    "    for bar in historical_data:\n",
    "        print(bar)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d65e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         date     open     high      low    close  volume  \\\n",
      "0   2024-02-15 08:30:00-06:00  5077.50  5088.75  5077.00  5081.25    -1.0   \n",
      "1   2024-02-15 09:00:00-06:00  5081.25  5090.75  5077.75  5082.75    -1.0   \n",
      "2   2024-02-15 10:00:00-06:00  5082.75  5086.25  5072.50  5082.75    -1.0   \n",
      "3   2024-02-15 11:00:00-06:00  5082.75  5090.75  5081.50  5085.50    -1.0   \n",
      "4   2024-02-15 12:00:00-06:00  5085.50  5102.00  5084.50  5099.00    -1.0   \n",
      "..                        ...      ...      ...      ...      ...     ...   \n",
      "235 2024-03-28 11:00:00-05:00  5314.75  5314.75  5307.50  5310.25    -1.0   \n",
      "236 2024-03-28 12:00:00-05:00  5310.25  5311.00  5305.00  5309.50    -1.0   \n",
      "237 2024-03-28 13:00:00-05:00  5309.50  5318.00  5305.25  5316.50    -1.0   \n",
      "238 2024-03-28 14:00:00-05:00  5316.50  5321.00  5303.25  5305.50    -1.0   \n",
      "239 2024-03-28 15:00:00-05:00  5305.50  5308.25  5302.00  5304.25    -1.0   \n",
      "\n",
      "     average  barCount  \n",
      "0       -1.0        -1  \n",
      "1       -1.0        -1  \n",
      "2       -1.0        -1  \n",
      "3       -1.0        -1  \n",
      "4       -1.0        -1  \n",
      "..       ...       ...  \n",
      "235     -1.0        -1  \n",
      "236     -1.0        -1  \n",
      "237     -1.0        -1  \n",
      "238     -1.0        -1  \n",
      "239     -1.0        -1  \n",
      "\n",
      "[240 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = util.df(historical_data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eaf9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = Order(action='SELL', totalQuantity=5, orderType='LMT', lmtPrice=5300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9790a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = ib.placeOrder(contract, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "88e729c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error 354, reqId 19: You are trying to submit an order without having market data for this instrument. IBKR strongly recommends against this kind of blind trading which may result in erroneous or unexpected trades. Restriction is specified in Precautionary Settings of Global Configuration/Presets.\n",
      "Canceled order: Trade(contract=Future(conId=533620665, symbol='ES', lastTradeDateOrContractMonth='20240315', multiplier='50', exchange='CME', currency='USD', localSymbol='ESH4', tradingClass='ES'), order=Order(orderId=19, clientId=1, action='BUY', totalQuantity=1, orderType='LMT', lmtPrice=5140), orderStatus=OrderStatus(orderId=19, status='Cancelled', filled=0.0, remaining=0.0, avgFillPrice=0.0, permId=0, parentId=0, lastFillPrice=0.0, clientId=0, whyHeld='', mktCapPrice=0.0), fills=[], log=[TradeLogEntry(time=datetime.datetime(2024, 3, 8, 19, 34, 37, 144366, tzinfo=datetime.timezone.utc), status='PendingSubmit', message='', errorCode=0), TradeLogEntry(time=datetime.datetime(2024, 3, 8, 19, 34, 37, 186370, tzinfo=datetime.timezone.utc), status='Cancelled', message='Error 354, reqId 19: You are trying to submit an order without having market data for this instrument. IBKR strongly recommends against this kind of blind trading which may result in erroneous or unexpected trades. Restriction is specified in Precautionary Settings of Global Configuration/Presets.', errorCode=354)], advancedError='')\n",
      "Error 1100, reqId -1: Connectivity between IBKR and Trader Workstation has been lost.\n",
      "Error 1102, reqId -1: Connectivity between IBKR and Trader Workstation has been restored - data maintained. All data farms are connected: usfarm.nj; usfuture; cashfarm; usfarm; ushmds; secdefil.\n",
      "Error 1100, reqId -1: Connectivity between IBKR and Trader Workstation has been lost.\n",
      "Error 1100, reqId -1: Connectivity between IBKR and Trader Workstation has been lost.\n",
      "Error 1100, reqId -1: Connectivity between IBKR and Trader Workstation has been lost.\n",
      "Error 1102, reqId -1: Connectivity between IBKR and Trader Workstation has been restored - data maintained. All data farms are connected: usfarm.nj; usfuture; cashfarm; usfarm; ushmds; secdefil.\n",
      "Error 1100, reqId -1: Connectivity between IBKR and Trader Workstation has been lost.\n",
      "Error 1102, reqId -1: Connectivity between IBKR and Trader Workstation has been restored - data maintained. All data farms are connected: usfarm.nj; usfuture; cashfarm; usfarm; ushmds; secdefil.\n",
      "Error 1100, reqId -1: Connectivity between IBKR and Trader Workstation has been lost.\n",
      "Error 1102, reqId -1: Connectivity between IBKR and Trader Workstation has been restored - data maintained. All data farms are connected: usfarm.nj; usfuture; cashfarm; usfarm; ushmds; secdefil.\n",
      "Error 1100, reqId -1: Connectivity between IBKR and Trader Workstation has been lost.\n",
      "Error 1102, reqId -1: Connectivity between IBKR and Trader Workstation has been restored - data maintained. All data farms are connected: usfarm.nj; usfuture; cashfarm; usfarm; ushmds; secdefil.\n",
      "Error 1100, reqId -1: Connectivity between IBKR and Trader Workstation has been lost.\n",
      "Error 1102, reqId -1: Connectivity between IBKR and Trader Workstation has been restored - data maintained. All data farms are connected: usfarm.nj; usfuture; cashfarm; usfarm; ushmds; secdefil.\n"
     ]
    }
   ],
   "source": [
    "order = Order(action='BUY', totalQuantity=1, orderType='LMT', lmtPrice=5140)\n",
    "trade = ib.placeOrder(contract, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "241072c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account Balance: 856736.50\n"
     ]
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "\n",
    "# Assuming 'ib' is already connected and is an instance of ib_insync.IB()\n",
    "\n",
    "# Use the asynchronous version of the accountSummary function with await\n",
    "account_summary = await ib.accountSummaryAsync()\n",
    "\n",
    "# Find the total cash balance\n",
    "balance = next((item for item in account_summary if item.tag == 'TotalCashBalance'), None)\n",
    "print(\"Account Balance:\", balance.value if balance else \"No balance found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d6012e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Running the main function\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 25\u001b[0m     \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/runners.py:33\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(main, debug)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     34\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m coroutines\u001b[38;5;241m.\u001b[39miscoroutine(main):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma coroutine was expected, got \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(main))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "def buy(tq, ot, lp):\n",
    "    order = Order(action='BUY', totalQuantity=tq, orderType=ot, lmtPrice=lp)\n",
    "    trade = ib.placeOrder(contract, order)\n",
    "def sell(tq, ot, lp):\n",
    "    order = Order(action='SELL', totalQuantity=tq, orderType=ot, lmtPrice=lp)\n",
    "    trade = ib.placeOrder(contract, order)  \n",
    "\n",
    "\n",
    "async def check_total_cash_balance():\n",
    "    try:\n",
    "        account_summary = await ib.accountSummaryAsync()\n",
    "        balance = next((item for item in account_summary if item.tag == 'TotalCashBalance'), None)\n",
    "        return balance.value  # Assuming 'balance' has a 'value' attribute.\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Async function to call and print the result of check_total_cash_balance\n",
    "async def main():\n",
    "    balance = await check_total_cash_balance()\n",
    "    print(balance)\n",
    "\n",
    "# Running the main function\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "504b6ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-97' coro=<IB.connectAsync() done, defined at /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ib_insync/ib.py:1739> exception=TimeoutError()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/tasks.py\", line 690, in _wrap_awaitable\n",
      "    return (yield from awaitable.__await__())\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/tasks.py\", line 492, in wait_for\n",
      "    fut.result()\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ib_insync/ib.py\", line 1748, in connectAsync\n",
      "    await self.client.connectAsync(host, port, clientId, timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ib_insync/client.py\", line 217, in connectAsync\n",
      "    await asyncio.wait_for(self.apiStart, timeout)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/asyncio/tasks.py\", line 494, in wait_for\n",
      "    raise exceptions.TimeoutError() from exc\n",
      "asyncio.exceptions.TimeoutError\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "403 Client Error: Forbidden for url: https://data.alpaca.markets/v2/stocks/AAPL/bars?timeframe=1Day&adjustment=raw&limit=10",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m api \u001b[38;5;241m=\u001b[39m tradeapi\u001b[38;5;241m.\u001b[39mREST(API_KEY, API_SECRET, base_url\u001b[38;5;241m=\u001b[39mBASE_URL, api_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Get stock data using get_bars instead of get_barset\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m bars \u001b[38;5;241m=\u001b[39m \u001b[43mapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bars\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAAPL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtradeapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTimeFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdf\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m bars\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(index, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhigh\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlow\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvolume\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/alpaca_trade_api/rest.py:735\u001b[0m, in \u001b[0;36mREST.get_bars\u001b[0;34m(self, symbol, timeframe, start, end, adjustment, limit, feed, asof, sort)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bars\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    725\u001b[0m              symbol: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    726\u001b[0m              timeframe: TimeFrame,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    733\u001b[0m              sort: Optional[Sort] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    734\u001b[0m              ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BarsV2:\n\u001b[0;32m--> 735\u001b[0m     bars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bars_iter\u001b[49m\u001b[43m(\u001b[49m\u001b[43msymbol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mtimeframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43madjustment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mfeed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    742\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43masof\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    743\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    744\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m BarsV2(bars)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/alpaca_trade_api/rest.py:718\u001b[0m, in \u001b[0;36mREST.get_bars_iter\u001b[0;34m(self, symbol, timeframe, start, end, adjustment, limit, feed, asof, sort, raw)\u001b[0m\n\u001b[1;32m    697\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_bars_iter\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    698\u001b[0m                   symbol: Union[\u001b[38;5;28mstr\u001b[39m, List[\u001b[38;5;28mstr\u001b[39m]],\n\u001b[1;32m    699\u001b[0m                   timeframe: TimeFrame,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    706\u001b[0m                   sort: Optional[Sort] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    707\u001b[0m                   raw\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BarIterator:\n\u001b[1;32m    708\u001b[0m     bars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_get(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbars\u001b[39m\u001b[38;5;124m'\u001b[39m, symbol,\n\u001b[1;32m    709\u001b[0m                           timeframe\u001b[38;5;241m=\u001b[39mtimeframe,\n\u001b[1;32m    710\u001b[0m                           adjustment\u001b[38;5;241m=\u001b[39madjustment,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    716\u001b[0m                           sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    717\u001b[0m                           )\n\u001b[0;32m--> 718\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m bar \u001b[38;5;129;01min\u001b[39;00m bars:\n\u001b[1;32m    719\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m raw:\n\u001b[1;32m    720\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m bar\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/alpaca_trade_api/rest.py:594\u001b[0m, in \u001b[0;36mREST._data_get\u001b[0;34m(self, endpoint, symbol_or_symbols, api_version, endpoint_base, resp_grouped_by_symbol, page_limit, feed, asof, loc, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m endpoint:\n\u001b[1;32m    593\u001b[0m     path \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 594\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_get\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_version\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m resp_grouped_by_symbol:\n\u001b[1;32m    597\u001b[0m     k \u001b[38;5;241m=\u001b[39m endpoint \u001b[38;5;129;01mor\u001b[39;00m endpoint_base\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/alpaca_trade_api/rest.py:274\u001b[0m, in \u001b[0;36mREST.data_get\u001b[0;34m(self, path, data, feed, api_version)\u001b[0m\n\u001b[1;32m    272\u001b[0m     data \u001b[38;5;241m=\u001b[39m data \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    273\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeed\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m feed\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mapi_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/alpaca_trade_api/rest.py:222\u001b[0m, in \u001b[0;36mREST._request\u001b[0;34m(self, method, path, data, base_url, api_version)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m retry \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 222\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m RetryException:\n\u001b[1;32m    224\u001b[0m         retry_wait \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_wait\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/alpaca_trade_api/rest.py:248\u001b[0m, in \u001b[0;36mREST._one_request\u001b[0;34m(self, method, url, opts, retry)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m retry_codes \u001b[38;5;129;01mand\u001b[39;00m retry \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    247\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RetryException()\n\u001b[0;32m--> 248\u001b[0m     \u001b[43mraise_api_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/alpaca_trade_api/rest.py:81\u001b[0m, in \u001b[0;36mraise_api_error\u001b[0;34m(resp, http_error)\u001b[0m\n\u001b[1;32m     79\u001b[0m     error \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m http_error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m error:\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIError(error, http_error) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/alpaca_trade_api/rest.py:243\u001b[0m, in \u001b[0;36mREST._one_request\u001b[0;34m(self, method, url, opts, retry)\u001b[0m\n\u001b[1;32m    241\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mopts)\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 243\u001b[0m     \u001b[43mresp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m# retry if we hit Rate Limit\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;129;01min\u001b[39;00m retry_codes \u001b[38;5;129;01mand\u001b[39;00m retry \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://data.alpaca.markets/v2/stocks/AAPL/bars?timeframe=1Day&adjustment=raw&limit=10"
     ]
    }
   ],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "# Set your API key and secret\n",
    "API_KEY = 'your_api_key'\n",
    "API_SECRET = 'your_api_secret'\n",
    "BASE_URL = 'https://paper-api.alpaca.markets'\n",
    "\n",
    "# Initialize the API connection\n",
    "api = tradeapi.REST(API_KEY, API_SECRET, base_url=BASE_URL, api_version='v2')\n",
    "\n",
    "# Get stock data using get_bars instead of get_barset\n",
    "bars = api.get_bars('AAPL', tradeapi.TimeFrame.Day, limit=10).df\n",
    "for index, row in bars.iterrows():\n",
    "    print(index, row['open'], row['high'], row['low'], row['close'], row['volume'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1278ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alpaca-trade-api\n",
      "  Obtaining dependency information for alpaca-trade-api from https://files.pythonhosted.org/packages/0b/b2/4557d0a4c837b020bc5c8971e8fde8b976e332d5c225476699e0b5e30b41/alpaca_trade_api-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading alpaca_trade_api-3.2.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pandas>=0.18.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpaca-trade-api) (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpaca-trade-api) (1.22.2)\n",
      "Requirement already satisfied: requests<3,>2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpaca-trade-api) (2.31.0)\n",
      "Requirement already satisfied: urllib3<2,>1.24 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpaca-trade-api) (1.26.16)\n",
      "Requirement already satisfied: websocket-client<2,>=0.56.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpaca-trade-api) (1.5.3)\n",
      "Collecting websockets<11,>=9.0 (from alpaca-trade-api)\n",
      "  Obtaining dependency information for websockets<11,>=9.0 from https://files.pythonhosted.org/packages/47/4d/f2e28f112302d3bc794b74ae64656255161d8223f4d47bd17d40cbb3629e/websockets-10.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading websockets-10.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting msgpack==1.0.3 (from alpaca-trade-api)\n",
      "  Obtaining dependency information for msgpack==1.0.3 from https://files.pythonhosted.org/packages/3a/57/c90cb0b1ab68650ff0068240449bc17c269069bd898cf283dc8db72e8788/msgpack-1.0.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading msgpack-1.0.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting aiohttp<4,>=3.8.3 (from alpaca-trade-api)\n",
      "  Obtaining dependency information for aiohttp<4,>=3.8.3 from https://files.pythonhosted.org/packages/20/1c/b7e668a1583cbb1e5060b45baee68a50123f66470ac463f81f7e3b3c3bab/aiohttp-3.9.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading aiohttp-3.9.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting PyYAML==6.0.1 (from alpaca-trade-api)\n",
      "  Obtaining dependency information for PyYAML==6.0.1 from https://files.pythonhosted.org/packages/57/c5/5d09b66b41d549914802f482a2118d925d876dc2a35b2d127694c1345c34/PyYAML-6.0.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting deprecation==2.1.0 (from alpaca-trade-api)\n",
      "  Obtaining dependency information for deprecation==2.1.0 from https://files.pythonhosted.org/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from deprecation==2.1.0->alpaca-trade-api) (21.3)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
      "  Obtaining dependency information for aiosignal>=1.1.2 from https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/4d/23/7f01123d0e5adcc65cbbde5731378237dea7db467abd19e391f1ddd4130d/frozenlist-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/7d/5c/c364a77b37f580cc28da4194b77ed04286c7631933d3e64fdae40f1972e2/multidict-6.0.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading multidict-6.0.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.0 from https://files.pythonhosted.org/packages/8f/0f/9fa6f044b04267d22ec29df23936ffd4bf4572ccecd889c6b2b1761c2c5c/yarl-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading yarl-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
      "  Obtaining dependency information for async-timeout<5.0,>=4.0 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=0.18.1->alpaca-trade-api) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=0.18.1->alpaca-trade-api) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=0.18.1->alpaca-trade-api) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>2->alpaca-trade-api) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>2->alpaca-trade-api) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>2->alpaca-trade-api) (2023.5.7)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=0.18.1->alpaca-trade-api) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging->deprecation==2.1.0->alpaca-trade-api) (3.0.7)\n",
      "Downloading alpaca_trade_api-3.2.0-py3-none-any.whl (34 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading msgpack-1.0.3-cp39-cp39-macosx_10_9_x86_64.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp39-cp39-macosx_10_9_x86_64.whl (197 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m197.8/197.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp39-cp39-macosx_10_9_x86_64.whl (398 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m398.8/398.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading websockets-10.4-cp39-cp39-macosx_10_9_x86_64.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp39-cp39-macosx_10_9_x86_64.whl (30 kB)\n",
      "Downloading yarl-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m83.7/83.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: msgpack, websockets, PyYAML, multidict, frozenlist, async-timeout, yarl, deprecation, aiosignal, aiohttp, alpaca-trade-api\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed PyYAML-6.0.1 aiohttp-3.9.3 aiosignal-1.3.1 alpaca-trade-api-3.2.0 async-timeout-4.0.3 deprecation-2.1.0 frozenlist-1.4.1 msgpack-1.0.3 multidict-6.0.5 websockets-10.4 yarl-1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install alpaca-trade-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cad39757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Not connected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m order \u001b[38;5;241m=\u001b[39m Order(action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBUY\u001b[39m\u001b[38;5;124m'\u001b[39m, totalQuantity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, orderType\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLMT\u001b[39m\u001b[38;5;124m'\u001b[39m, lmtPrice\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5200\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m trade \u001b[38;5;241m=\u001b[39m \u001b[43mib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceOrder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontract\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ib_insync/ib.py:654\u001b[0m, in \u001b[0;36mIB.placeOrder\u001b[0;34m(self, contract, order)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplaceOrder\u001b[39m(\u001b[38;5;28mself\u001b[39m, contract: Contract, order: Order) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Trade:\n\u001b[1;32m    645\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;124;03m    Place a new order or modify an existing order.\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m    Returns a Trade that is kept live updated with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;124;03m        order: The order to be placed.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 654\u001b[0m     orderId \u001b[38;5;241m=\u001b[39m order\u001b[38;5;241m.\u001b[39morderId \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetReqId\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mplaceOrder(orderId, contract, order)\n\u001b[1;32m    656\u001b[0m     now \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow(datetime\u001b[38;5;241m.\u001b[39mtimezone\u001b[38;5;241m.\u001b[39mutc)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ib_insync/client.py:160\u001b[0m, in \u001b[0;36mClient.getReqId\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get new request ID.\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misReady():\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot connected\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    161\u001b[0m newId \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reqIdSeq\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reqIdSeq \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mConnectionError\u001b[0m: Not connected"
     ]
    }
   ],
   "source": [
    "order = Order(action='BUY', totalQuantity=100, orderType='LMT', lmtPrice=5200)\n",
    "trade = ib.placeOrder(contract, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9286490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (24.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a92a535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-02 00:00:00-04:00 58.56 59.65 58.51 59.31 301281\n",
      "close price 59.31\n"
     ]
    }
   ],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "# Set your API key and secret\n",
    "API_KEY = 'PKHIU3GSGREXWZOJSIP2'\n",
    "API_SECRET = 'Gi1lOxqYrvvLb3PMNEMEnqa4b0IRTbG73GZEbWVf'\n",
    "BASE_URL = 'https://paper-api.alpaca.markets'  # or 'https://api.alpaca.markets' for live trading\n",
    "\n",
    "# Initialize the API connection\n",
    "api = tradeapi.REST(API_KEY, API_SECRET, base_url=BASE_URL, api_version='v2')\n",
    "\n",
    "# Get stock data\n",
    "barset = api.get_bars('ES', '1D', limit=10)\n",
    "# aapl_bars = barset['AAPL']\n",
    "for bar in barset:\n",
    "    print(bar.t, bar.o, bar.h, bar.l, bar.c, bar.v)\n",
    "    print(\"close price\", bar.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af4494af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for AAPL:\n",
      "Timestamp: 2024-02-21 00:00:00-05:00\n",
      "Open: 181.94\n",
      "High: 182.8888\n",
      "Low: 180.66\n",
      "Close: 182.32\n",
      "Volume: 41529674\n",
      "\n",
      "Timestamp: 2024-02-22 00:00:00-05:00\n",
      "Open: 183.48\n",
      "High: 184.955\n",
      "Low: 182.46\n",
      "Close: 184.37\n",
      "Volume: 52292208\n",
      "\n",
      "Timestamp: 2024-02-23 00:00:00-05:00\n",
      "Open: 185.01\n",
      "High: 185.04\n",
      "Low: 182.23\n",
      "Close: 182.52\n",
      "Volume: 45096195\n",
      "\n",
      "Timestamp: 2024-02-26 00:00:00-05:00\n",
      "Open: 182.24\n",
      "High: 182.76\n",
      "Low: 180.65\n",
      "Close: 181.16\n",
      "Volume: 40867421\n",
      "\n",
      "Timestamp: 2024-02-27 00:00:00-05:00\n",
      "Open: 181.1\n",
      "High: 183.9225\n",
      "Low: 179.56\n",
      "Close: 182.63\n",
      "Volume: 54319745\n",
      "\n",
      "Timestamp: 2024-02-28 00:00:00-05:00\n",
      "Open: 182.51\n",
      "High: 183.12\n",
      "Low: 180.13\n",
      "Close: 181.42\n",
      "Volume: 48953939\n",
      "\n",
      "Timestamp: 2024-02-29 00:00:00-05:00\n",
      "Open: 181.27\n",
      "High: 182.57\n",
      "Low: 179.53\n",
      "Close: 180.75\n",
      "Volume: 136640307\n",
      "\n",
      "Timestamp: 2024-03-01 00:00:00-05:00\n",
      "Open: 179.55\n",
      "High: 180.53\n",
      "Low: 177.38\n",
      "Close: 179.66\n",
      "Volume: 73563184\n",
      "\n",
      "Timestamp: 2024-03-04 00:00:00-05:00\n",
      "Open: 176.15\n",
      "High: 176.9\n",
      "Low: 173.79\n",
      "Close: 175.1\n",
      "Volume: 81510101\n",
      "\n",
      "Timestamp: 2024-03-05 00:00:00-05:00\n",
      "Open: 170.76\n",
      "High: 172.04\n",
      "Low: 169.62\n",
      "Close: 170.12\n",
      "Volume: 95432355\n",
      "\n",
      "Timestamp: 2024-03-06 00:00:00-05:00\n",
      "Open: 171.06\n",
      "High: 171.24\n",
      "Low: 168.68\n",
      "Close: 169.12\n",
      "Volume: 68587707\n",
      "\n",
      "Timestamp: 2024-03-07 00:00:00-05:00\n",
      "Open: 169.15\n",
      "High: 170.73\n",
      "Low: 168.49\n",
      "Close: 169\n",
      "Volume: 71765061\n",
      "\n",
      "Timestamp: 2024-03-08 00:00:00-05:00\n",
      "Open: 169\n",
      "High: 173.7\n",
      "Low: 168.94\n",
      "Close: 170.73\n",
      "Volume: 76159346\n",
      "\n",
      "Timestamp: 2024-03-11 00:00:00-04:00\n",
      "Open: 172.94\n",
      "High: 174.38\n",
      "Low: 172.05\n",
      "Close: 172.75\n",
      "Volume: 60139473\n",
      "\n",
      "Timestamp: 2024-03-12 00:00:00-04:00\n",
      "Open: 173.15\n",
      "High: 174.03\n",
      "Low: 171.01\n",
      "Close: 173.23\n",
      "Volume: 59825372\n",
      "\n",
      "Timestamp: 2024-03-13 00:00:00-04:00\n",
      "Open: 172.77\n",
      "High: 173.185\n",
      "Low: 170.76\n",
      "Close: 171.13\n",
      "Volume: 52488692\n",
      "\n",
      "Timestamp: 2024-03-14 00:00:00-04:00\n",
      "Open: 172.91\n",
      "High: 174.3078\n",
      "Low: 172.05\n",
      "Close: 173\n",
      "Volume: 72913507\n",
      "\n",
      "Timestamp: 2024-03-15 00:00:00-04:00\n",
      "Open: 171.17\n",
      "High: 172.62\n",
      "Low: 170.285\n",
      "Close: 172.62\n",
      "Volume: 121752699\n",
      "\n",
      "Timestamp: 2024-03-18 00:00:00-04:00\n",
      "Open: 175.57\n",
      "High: 177.71\n",
      "Low: 173.52\n",
      "Close: 173.72\n",
      "Volume: 75604184\n",
      "\n",
      "Timestamp: 2024-03-19 00:00:00-04:00\n",
      "Open: 174.34\n",
      "High: 176.605\n",
      "Low: 173.03\n",
      "Close: 176.08\n",
      "Volume: 55215244\n",
      "\n",
      "Timestamp: 2024-03-20 00:00:00-04:00\n",
      "Open: 175.72\n",
      "High: 178.67\n",
      "Low: 175.09\n",
      "Close: 178.67\n",
      "Volume: 53423102\n",
      "\n",
      "Timestamp: 2024-03-21 00:00:00-04:00\n",
      "Open: 177.05\n",
      "High: 177.49\n",
      "Low: 170.84\n",
      "Close: 171.37\n",
      "Volume: 106181270\n",
      "\n",
      "Timestamp: 2024-03-22 00:00:00-04:00\n",
      "Open: 171.76\n",
      "High: 173.05\n",
      "Low: 170.06\n",
      "Close: 172.28\n",
      "Volume: 71160138\n",
      "\n",
      "Timestamp: 2024-03-25 00:00:00-04:00\n",
      "Open: 170.565\n",
      "High: 171.94\n",
      "Low: 169.45\n",
      "Close: 170.85\n",
      "Volume: 54288328\n",
      "\n",
      "Timestamp: 2024-03-26 00:00:00-04:00\n",
      "Open: 170\n",
      "High: 171.42\n",
      "Low: 169.58\n",
      "Close: 169.71\n",
      "Volume: 57388449\n",
      "\n",
      "Timestamp: 2024-03-27 00:00:00-04:00\n",
      "Open: 170.41\n",
      "High: 173.6\n",
      "Low: 170.11\n",
      "Close: 173.31\n",
      "Volume: 60273265\n",
      "\n",
      "Timestamp: 2024-03-28 00:00:00-04:00\n",
      "Open: 171.75\n",
      "High: 172.23\n",
      "Low: 170.51\n",
      "Close: 171.48\n",
      "Volume: 65672690\n",
      "\n",
      "Timestamp: 2024-04-01 00:00:00-04:00\n",
      "Open: 171.19\n",
      "High: 171.25\n",
      "Low: 169.475\n",
      "Close: 170.03\n",
      "Volume: 46240500\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "try:\n",
    "    # Calculate the start and end dates for the last 5 days\n",
    "    end_date = datetime.today() - timedelta(days=1)  # Fetch data until yesterday\n",
    "    start_date = end_date - timedelta(days=40)  # Fetch data from 5 days ago\n",
    "\n",
    "    # Format dates in ISO 8601 format (YYYY-MM-DD)\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Define the symbols, timeframe, and limit\n",
    "    symbols = ['AAPL']  # Add more symbols as needed\n",
    "    timeframe = '1D'  # Daily bars\n",
    "    limit = 40  # Number of bars to fetch, fetch data for the last 5 days\n",
    "\n",
    "    # Create an empty dictionary to store historical data for each symbol\n",
    "    historical_data = {}\n",
    "\n",
    "    # Fetch historical data for each symbol\n",
    "    for symbol in symbols:\n",
    "        barset = api.get_bars(symbol, timeframe, start=start_date_str, end=end_date_str, limit=limit)\n",
    "\n",
    "        # Store the BarSet object in the dictionary\n",
    "        historical_data[symbol] = barset\n",
    "\n",
    "    # Print the fetched data for each symbol\n",
    "    for symbol, barset in historical_data.items():\n",
    "        print(f\"Data for {symbol}:\")\n",
    "        for bar in barset:\n",
    "            print(\"Timestamp:\", bar.t)\n",
    "            print(\"Open:\", bar.o)\n",
    "            print(\"High:\", bar.h)\n",
    "            print(\"Low:\", bar.l)\n",
    "            print(\"Close:\", bar.c)\n",
    "            print(\"Volume:\", bar.v)\n",
    "            print()  # Add a newline for clarity between bars\n",
    "        print()  # Add an extra newline for clarity between symbols\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "705642a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alpha_vantage\n",
      "  Obtaining dependency information for alpha_vantage from https://files.pythonhosted.org/packages/ba/b4/d95f9e0eccea6732bab5a079772d453a4f0b68a9f63740d9cf320f92beaa/alpha_vantage-2.3.1-py3-none-any.whl.metadata\n",
      "  Downloading alpha_vantage-2.3.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpha_vantage) (3.9.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpha_vantage) (2.31.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->alpha_vantage) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->alpha_vantage) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->alpha_vantage) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->alpha_vantage) (2023.5.7)\n",
      "Downloading alpha_vantage-2.3.1-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: alpha_vantage\n",
      "Successfully installed alpha_vantage-2.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install alpha_vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b029a376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            1. open  2. high  3. low  4. close  5. volume\n",
      "date                                                     \n",
      "2024-04-01    59.71   59.710  58.525     58.88  1503051.0\n",
      "2024-03-28    59.27   59.985  58.800     59.77  1921036.0\n",
      "2024-03-27    56.91   58.990  56.910     58.98  2840904.0\n",
      "2024-03-26    57.49   57.820  56.160     56.29  2165646.0\n",
      "2024-03-25    57.89   58.250  57.190     57.52  1923841.0\n",
      "...             ...      ...     ...       ...        ...\n",
      "2023-11-10    54.57   54.750  53.625     53.80  2398277.0\n",
      "2023-11-09    55.97   56.130  54.210     54.24  2427103.0\n",
      "2023-11-08    56.17   56.340  54.900     55.69  2249165.0\n",
      "2023-11-07    56.37   57.640  55.630     56.35  3137947.0\n",
      "2023-11-06    54.83   56.610  54.690     56.56  5270655.0\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "# Set your API key\n",
    "API_KEY = 'your_api_key'\n",
    "\n",
    "# Initialize the API connection\n",
    "ts = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "\n",
    "# Get stock data\n",
    "data, metadata = ts.get_daily(symbol='ES', outputsize='compact')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7ee2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set the URL for MarketAux\n",
    "url = 'https://www.marketaux.com/'\n",
    "\n",
    "try:\n",
    "    # Send a request to the website and parse the HTML content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an error for bad status codes\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract financial headlines\n",
    "    headlines = soup.find_all('h2', class_='entry-title')\n",
    "    for headline in headlines:\n",
    "        print(headline.text)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f5c87c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 'invalid_api_token', 'message': 'An invalid API token was supplied.'}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m# Append the article's title to the list of headlines for this date\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         headlines[date_str]\u001b[38;5;241m.\u001b[39mappend(article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 37\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mget_headlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m extract_headlines(data)\n",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m, in \u001b[0;36mget_headlines\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m news_headlines \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(news_headlines)  \u001b[38;5;66;03m# Print the response content\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnews_headlines\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     13\u001b[0m     date \u001b[38;5;241m=\u001b[39m article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublished_at\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m     title \u001b[38;5;241m=\u001b[39m article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def get_headlines():\n",
    "    url = \"https://api.marketaux.com/v1/news/all?symbols=^GSPC&filter_entities=true&language=en&api_token=\"\n",
    "    \n",
    "    cleaned_data = []\n",
    "    for _ in range(3):\n",
    "        response = requests.get(url)\n",
    "        news_headlines = response.json()\n",
    "        print(news_headlines)  # Print the response content\n",
    "        for article in news_headlines['data']:\n",
    "            date = article['published_at']\n",
    "            title = article['title']\n",
    "            cleaned_data.append({'date': date, 'headline': title})\n",
    "    \n",
    "    return cleaned_data\n",
    "\n",
    "def extract_headlines(data):\n",
    "    # Initialize an empty dictionary to hold the headlines\n",
    "    headlines = {}\n",
    "    \n",
    "    # Loop through each article in the data file\n",
    "    for article in data['articles']:\n",
    "        # Extract the date from the 'publishedAt' field and convert it to a datetime object\n",
    "        date = parse(article['publishedAt']).date()\n",
    "        \n",
    "        # Convert the date to a string in the format 'YYYY-MM-DD'\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # If the date is not already in the headlines dictionary, add it with an empty list as the value\n",
    "        if date_str not in headlines:\n",
    "            headlines[date_str] = []\n",
    "        \n",
    "        # Append the article's title to the list of headlines for this date\n",
    "        headlines[date_str].append(article['title'])\n",
    "data = get_headlines()\n",
    "extract_headlines(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "563fc0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Information\n",
      "2. Symbol\n",
      "3. Last Refreshed\n",
      "4. Output Size\n",
      "5. Time Zone\n"
     ]
    }
   ],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "# Set your API key\n",
    "API_KEY = 'your_api_key'\n",
    "\n",
    "# Initialize the API connection\n",
    "ts = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "\n",
    "# Get stock data\n",
    "data, metadata = ts.get_daily(symbol='AAPL', outputsize='compact')\n",
    "for d in metadata:\n",
    "    \n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed56935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Data to be written to the CSV file\n",
    "data = [\n",
    "    [\"Name\", \"Age\", \"City\"],\n",
    "    [\"Alice\", 30, \"New York\"],\n",
    "    [\"Bob\", 25, \"Los Angeles\"],\n",
    "    [\"Charlie\", 35, \"Chicago\"]\n",
    "]\n",
    "\n",
    "# Opening the CSV file and writing the data\n",
    "with open('people.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"CSV file has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64d76e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   30     New York\n",
      "1      Bob   25  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the CSV file name\n",
    "filename = 'people.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "938dd821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: name 'api' is not defined\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe256672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request error: 404 Client Error: Not Found for url: https://api.marketaux.com/v1/news/?api_key=EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual MarketAux API key\n",
    "api_key = 'EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj'\n",
    "endpoint = 'https://api.marketaux.com/v1/news/'\n",
    "params = {\n",
    "    'api_key': api_key,\n",
    "    # Add any other required parameters according to the API documentation\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Make the request to the MarketAux API\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    response.raise_for_status()  # Raise an error for bad status codes\n",
    "\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    # Assuming the JSON response contains a list of headlines under 'data' key\n",
    "    for headline in data.get('data', []):\n",
    "        print(headline['title'])  # Adjust the key according to the actual response structure\n",
    "        \n",
    "#     response = requests.get(endpoint, params=params)\n",
    "#     response.raise_for_status()  # Raise an error for bad status codes\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#     # Extract financial headlines\n",
    "#     # Note: The 'h2' and 'entry-title' class are assumptions. \n",
    "#     # Please verify and adjust according to the website's current HTML structure.\n",
    "#     headlines = soup.find_all('h2', class_='entry-title')\n",
    "    \n",
    "except requests.RequestException as e:\n",
    "    print(f\"Request error: {e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"JSON decode error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3f7331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digital Identity Solutions Provider Signicat Acquires SmartWorks\n",
      "Ontario Newsroom\n",
      "Alkhaleej Training board proposes withholding dividends for 2023\n",
      "STMicroelectronics NV at Citi TMT Conference Transcript\n",
      "CaixaBank SA Annual Shareholders Meeting Transcript\n",
      "Kijiji Scammers and General Idiots\n",
      "Securitas AB Investor Day Transcript\n",
      "Our Economy and Politics Are Broken\n",
      "Full Year 2023 Wendel SE Earnings Call Transcript\n",
      "Side hustles transforming into profitable ventures\n",
      "End of Day Message\n",
      "Word-Of-Mouth Is Still How To Get Customers\n",
      "East Pipes inks SAR 230M supply contract with SWCC\n",
      "Modern Mills to make debut on TASI on March 27\n",
      "RBL Bank aims to grow retail with new products, cut back on wholesale book\n",
      "Jefferies raises LVMH target to EUR790 on steady market share By Investing.com\n",
      "AXA SA at Morgan Stanley European Financials Conference Transcript\n",
      "Quinta Brunson To Receive Honorary Degree From Temple University\n",
      "Rising Interest Costs Squeeze Junk-Rated US Companies Amid Fed Rate Hikes\n",
      "20 Best Countries for Migration by Investment\n",
      "20 Best Countries for Migration by Investment\n",
      "Binance Labs Invests in StakeStone As It Continues to Bet Big On Restaking Sector\n",
      "Binance Labs Invests in StakeStone As It Continues to Bet Big On Restaking Sector\n",
      "Israel-US relations hit new low after US abstention at UN\n",
      "AMLO respalda el llamado de la ONU a un alto el fuego en Gaza\n",
      "5 Best Countries for Migration by Investment\n",
      "Transaction in Own Shares\n",
      "Putin says Moscow attack committed by radical Islamists\n",
      "Elon Musk Asks Why Ethereum Co-Creator Vitalik Buterin Left X\n",
      "Super Micro Stock Jumps After Bullish Call From JPMorgan\n",
      "How to improve confidence in ETFs\n",
      "OXURION announces its presence at the Paris SmallCap event on March 28, 2024.\n",
      "Netherlands fact of the day\n",
      "An 1,800-year-old Roman statue was found in a UK parking lot. How it got there is a mystery.\n",
      "Bitcoin Erupts Higher In Epic Futures Short Squeeze\n",
      "US Solar Fund ups dividend despite drop in NAV\n",
      "Deutsche Bank AG at Morgan Stanley European Financials Conference Transcript\n",
      "Q4 2023 Telia Company AB Earnings Call Transcript\n",
      "Mining scam accused Janardhan Reddy returns to BJP\n",
      "Ludwig Lachmann Biography\n",
      "15 Hungriest States in the US\n",
      "My Freighter Leases Third 767 from ATSG\n",
      "Evercore ISI maintient son opinion sur Apple avec un objectif de 220 dollars Par Investing.com\n",
      "Forgetting something\n",
      "GRWS, CEG, and HTOO are among utility movers\n",
      "Gifting expert reveals Easter chocolate might be out\n",
      "Tory Lanez Earns A New Billboard Chart Hit From Prison\n",
      "How To Unclutter Your Mind\n",
      "4E Exchange Signs Global Sponsorship Contract with Argentina National Football Team to Write a New Chapter of Sports and Finance\n",
      "Ryanair CEO Welcomes Leadership Changes At Boeing\n",
      "5 Hungriest States in the US\n",
      "Agricultural Survey\n",
      "How Athleisure Brands Like Vuori Are Harnessing NIL Influencers\n",
      "Kubicki fordert Einrichtung eines Nationalen Sicherheitsrat\n",
      "Boeing CEO to step down amid safety concerns\n",
      "Senegal election a welcome boost for coup-prone West Africa By Reuters\n",
      "How Athleisure Brands Like Vuori Are Harnessing NIL Influencers\n",
      "Kubicki fordert Einrichtung eines Nationalen Sicherheitsrat\n",
      "Boeing CEO to step down amid safety concerns\n",
      "Senegal election a welcome boost for coup-prone West Africa By Reuters\n",
      "China needs Apple even as it tries to push foreign firms out, economist says\n",
      "Elon Musk says Tesla and SpaceX are collaborating on the new Roadster\n",
      "Ericsson to lay off 1,200 staff in Sweden as 5G spending slows\n",
      "Media Finance Capital Opens New Avenues For Investors Seeking To Diversify Into Media Space\n",
      "Dow Jones Giant Verizon, Google Stock Near New Buy Points\n",
      "A New Wave of Optimism Reawakens the Bulls\n",
      "3 Wide-Moat Stocks That Could Triple By 2030\n",
      "Why HR Gets Wrongly Blamed For Management Problems\n",
      "California police asked to stop using Lego heads to disguise suspects\n",
      "LSE Opens Doors to Bitcoin and Ethereum ETN Applications\n",
      "MIS inks framework agreement with EXPRO to supply Microsoft products, services\n",
      "Giant Eagle expands DoorDash same-day delivery\n",
      "Rose Blood - A Friday The 13th Fan Film\n",
      "Friday The 13th Rose Blood - Legacy Campaign\n",
      "Reddit options launch draws bulls as shares extend gains By Reuters\n",
      "Rose Blood - The Final Campaign\n",
      "Rose Blood - The FINAL BLOOD Campaign\n",
      "Training und Wissen\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "402 Client Error: Payment Required for url: https://api.marketaux.com/v1/news/all?api_token=EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj&languages=en&page=101",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m page \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     headlines, max_pages \u001b[38;5;241m=\u001b[39m \u001b[43mget_a_page_of_headlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m headline \u001b[38;5;129;01min\u001b[39;00m headlines:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_nicely(headline):\n",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m, in \u001b[0;36mget_a_page_of_headlines\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m     10\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.marketaux.com/v1/news/all?\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m json \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]], json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturned\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 402 Client Error: Payment Required for url: https://api.marketaux.com/v1/news/all?api_token=EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj&languages=en&page=101"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "languages = [\"en\"]\n",
    "doneglyphs = \" ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,-\"\n",
    "API_TOKEN = \"EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj\"\n",
    "\n",
    "def get_a_page_of_headlines(page):\n",
    "    params = urlencode({\"api_token\": API_TOKEN, \"languages\": \",\".join(languages), \"page\": page})\n",
    "    url = f\"https://api.marketaux.com/v1/news/all?{params}\"\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    json = r.json()\n",
    "    return ([x.get(\"title\") for x in json[\"data\"]], json[\"meta\"][\"found\"] / json[\"meta\"][\"returned\"])\n",
    "\n",
    "def filter_nicely(headline):\n",
    "    # We could make exceptions for special cases here - check if we have\n",
    "    # punctuation in our supported list and drop punctuation if not, etc.\n",
    "    # But for now, the simple \"do we have all the characters in the headline?\"\n",
    "    if all((g in doneglyphs) for g in headline):\n",
    "        return headline\n",
    "\n",
    "page = 1\n",
    "while True:\n",
    "    headlines, max_pages = get_a_page_of_headlines(page)\n",
    "    for headline in headlines:\n",
    "        if filter_nicely(headline):\n",
    "            print(headline)\n",
    "    page += 1\n",
    "    if page > max_pages:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12406ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tweepy) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2023.5.7)\n",
      "Downloading tweepy-4.14.0-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tweepy\n",
      "Successfully installed tweepy-4.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0212920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.39.2-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Downloading filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (1.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp39-cp39-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.2-cp39-cp39-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (2023.5.7)\n",
      "Downloading transformers-4.39.2-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp39-cp39-macosx_10_9_x86_64.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp39-cp39-macosx_10_12_x86_64.whl (426 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m426.4/426.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp39-cp39-macosx_10_12_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.3-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.13.3 fsspec-2024.3.1 huggingface-hub-0.22.2 regex-2023.12.25 safetensors-0.4.2 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.39.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1091a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\n89 - Invalid or expired token.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnauthorized\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 96\u001b[0m\n\u001b[1;32m     92\u001b[0m         place_order(ib, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSELL\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Placeholder logic for demonstration\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m#     asyncio.run(main())\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mfetch_tweets_about_sp500\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mok\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 35\u001b[0m, in \u001b[0;36mfetch_tweets_about_sp500\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfetch_tweets_about_sp500\u001b[39m():\n\u001b[0;32m---> 35\u001b[0m     tweets \u001b[38;5;241m=\u001b[39m \u001b[43mtwitter_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_tweets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mS&P 500 OR SP500\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43men\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [tweet\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweets]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tweepy/api.py:33\u001b[0m, in \u001b[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tweepy/api.py:46\u001b[0m, in \u001b[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_list\n\u001b[1;32m     45\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_type\n\u001b[0;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tweepy/api.py:1146\u001b[0m, in \u001b[0;36mAPI.search_tweets\u001b[0;34m(self, q, **kwargs)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;129m@pagination\u001b[39m(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;129m@payload\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_results\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_tweets\u001b[39m(\u001b[38;5;28mself\u001b[39m, q, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;124;03m                     until, since_id, max_id, include_entities)\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    .. _Twitter's documentation on the standard search API: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/overview\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearch/tweets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint_parameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mq\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeocode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlang\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlocale\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mresult_type\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcount\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muntil\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msince_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43minclude_entities\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tweepy/api.py:269\u001b[0m, in \u001b[0;36mAPI.request\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequest(resp)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m401\u001b[39m:\n\u001b[0;32m--> 269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(resp)\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Forbidden(resp)\n",
      "\u001b[0;31mUnauthorized\u001b[0m: 401 Unauthorized\n89 - Invalid or expired token."
     ]
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import asyncio\n",
    "import tweepy\n",
    "from transformers import pipeline\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpaca_trade_api.rest import REST as AlpacaAPI\n",
    "\n",
    "# Twitter API for sentiment analysis\n",
    "api_key = \"your_twitter_api_key\"\n",
    "api_key_secret = \"your_twitter_api_key_secret\"\n",
    "access_token = \"your_access_token\"\n",
    "access_token_secret = \"your_access_token_secret\"\n",
    "\n",
    "# Alpaca and Alpha Vantage API keys\n",
    "ALPACA_API_KEY = 'your_alpaca_api_key'\n",
    "ALPACA_SECRET_KEY = 'your_alpaca_secret_key'\n",
    "ALPACA_ENDPOINT = 'https://paper-api.alpaca.markets'\n",
    "ALPHA_VANTAGE_API_KEY = 'your_alpha_vantage_api_key'\n",
    "\n",
    "# Initialize Twitter API\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "twitter_api = tweepy.API(auth)\n",
    "\n",
    "# Initialize Alpaca API\n",
    "alpaca_api = AlpacaAPI(ALPACA_API_KEY, ALPACA_SECRET_KEY, base_url=ALPACA_ENDPOINT)\n",
    "\n",
    "def fetch_tweets_about_sp500():\n",
    "    tweets = twitter_api.search_tweets(q=\"S&P 500 OR SP500\", lang=\"en\", count=100)\n",
    "    return [tweet.text for tweet in tweets]\n",
    "\n",
    "def analyze_sentiment(tweets):\n",
    "    sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "    results = sentiment_pipeline(tweets)\n",
    "    sentiment_score = sum([1 if res['label'] == 'POSITIVE' else -1 for res in results]) / len(results)\n",
    "    return sentiment_score\n",
    "\n",
    "def fetch_market_data_alpaca(symbol, start_date, end_date):\n",
    "    barset = alpaca_api.get_barset(symbol, 'day', start=start_date, end=end_date)\n",
    "    data = barset[symbol]\n",
    "    df = pd.DataFrame({\n",
    "        'time': [bar.t for bar in data],\n",
    "        'open': [bar.o for bar in data],\n",
    "        'high': [bar.h for bar in data],\n",
    "        'low': [bar.l for bar in data],\n",
    "        'close': [bar.c for bar in data],\n",
    "        'volume': [bar.v for bar in data]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def preprocess_and_save_data(data, filename='preprocessed_data.csv'):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data['close'].values.reshape(-1,1))\n",
    "    preprocessed_df = pd.DataFrame(scaled_data, columns=['Scaled_Close'])\n",
    "    preprocessed_df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "    return scaled_data\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def place_order(ib, action, quantity, price=None):\n",
    "    contract = Future('ES', '202406', 'GLOBEX')\n",
    "    order = MarketOrder(action, quantity) if not price else LimitOrder(action, quantity, price)\n",
    "    trade = ib.placeOrder(contract, order)\n",
    "    print(f\"Placed {action} order for {quantity} units.\")\n",
    "\n",
    "async def main():\n",
    "    ib = IB()\n",
    "    await ib.connectAsync('127.0.0.1', 7497, clientId=1)\n",
    "    \n",
    "    df = fetch_market_data_alpaca('SPY', '2023-01-01', '2023-12-31')\n",
    "    preprocessed_data = preprocess_and_save_data(df, 'market_data_preprocessed.csv')\n",
    "    \n",
    "    tweets = fetch_tweets_about_sp500()\n",
    "    sentiment_score = analyze_sentiment(tweets)\n",
    "    \n",
    "    if sentiment_score > 0:\n",
    "        place_order(ib, 'BUY', 1)  # Placeholder logic for demonstration\n",
    "    else:\n",
    "        place_order(ib, 'SELL', 1)  # Placeholder logic for demonstration\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())\n",
    "    print(fetch_tweets_about_sp500())\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed0c4f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           close     high      low  trade_count   open  \\\n",
      "timestamp                                                                \n",
      "2023-03-29 04:00:00+00:00  77.55  77.7000  76.4700        19362  76.47   \n",
      "2023-03-30 04:00:00+00:00  78.11  78.2300  77.3422        17649  77.75   \n",
      "2023-03-31 04:00:00+00:00  78.26  78.4800  77.4700        22882  78.38   \n",
      "2023-04-03 04:00:00+00:00  77.41  78.0500  76.7250        20804  77.55   \n",
      "2023-04-04 04:00:00+00:00  78.05  78.2200  77.3100        18834  77.57   \n",
      "...                          ...      ...      ...          ...    ...   \n",
      "2024-03-22 04:00:00+00:00  57.89  58.5979  57.7800        25632  58.40   \n",
      "2024-03-25 04:00:00+00:00  57.52  58.2500  57.1900        22316  57.89   \n",
      "2024-03-26 04:00:00+00:00  56.29  57.8200  56.1600        28317  57.49   \n",
      "2024-03-27 04:00:00+00:00  58.98  58.9900  56.9100        35032  56.91   \n",
      "2024-03-28 04:00:00+00:00  59.77  59.9850  58.8000        22759  59.27   \n",
      "\n",
      "                            volume       vwap  \n",
      "timestamp                                      \n",
      "2023-03-29 04:00:00+00:00  1510216  77.388629  \n",
      "2023-03-30 04:00:00+00:00  1092153  77.932173  \n",
      "2023-03-31 04:00:00+00:00  1734906  78.098744  \n",
      "2023-04-03 04:00:00+00:00  1676027  77.469674  \n",
      "2023-04-04 04:00:00+00:00  1072394  77.890656  \n",
      "...                            ...        ...  \n",
      "2024-03-22 04:00:00+00:00  2157059  58.002319  \n",
      "2024-03-25 04:00:00+00:00  1923841  57.506468  \n",
      "2024-03-26 04:00:00+00:00  2165646  56.541763  \n",
      "2024-03-27 04:00:00+00:00  2840904  58.494718  \n",
      "2024-03-28 04:00:00+00:00  1921036  59.677786  \n",
      "\n",
      "[252 rows x 7 columns]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tweepy\n",
    "from transformers import pipeline\n",
    "from alpaca_trade_api.rest import REST, TimeFrame\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Calculate the start and end dates for the last 5 days\n",
    "end_date = datetime.today() - timedelta(days=1)  # Fetch data until yesterday\n",
    "start_date = end_date - timedelta(days=365)  # Fetch data from 5 days ago\n",
    "\n",
    "# Format dates in ISO 8601 format (YYYY-MM-DD)\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "# Initialize Alpaca API\n",
    "ALPACA_API_KEY = 'PKHIU3GSGREXWZOJSIP2'\n",
    "ALPACA_SECRET_KEY = 'Gi1lOxqYrvvLb3PMNEMEnqa4b0IRTbG73GZEbWVf'\n",
    "alpaca_api = REST(ALPACA_API_KEY, ALPACA_SECRET_KEY, base_url='https://paper-api.alpaca.markets')\n",
    "\n",
    "# Initialize Twitter API\n",
    "auth = tweepy.OAuthHandler(\"FOzAGryMn6KTGhZ4oCPXZrwDw\", \"D9EUFQU5x9yk47UVPipGltuokzVeE3JZ9fScogcNmwHaRgrOwF\")\n",
    "auth.set_access_token(\"1773744788291960837-2eaPvcMt0ADfRsxSMNy77QN4kjb874\", \"uiPMWeX1UVOa7qRYylvaRXaEqRQ8qIgQgBjvkSLGdleim\")\n",
    "twitter_api = tweepy.API(auth)\n",
    "\n",
    "# Initialize Transformers Pipeline for Sentiment Analysis\n",
    "\n",
    "# sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "def fetch_market_data(symbol, start_date, end_date):\n",
    "    data = alpaca_api.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n",
    "    return data\n",
    "\n",
    "# def fetch_tweets_about_sp500(count=1):\n",
    "#     tweets = twitter_api.search_tweets(q=\"S&P 500 OR SP500\", lang=\"en\", result_type=\"recent\", count=count)\n",
    "#     return [tweet.text for tweet in tweets]\n",
    "\n",
    "def analyze_sentiment(tweets):\n",
    "    results = sentiment_pipeline(tweets)\n",
    "    scores = [1 if res['label'] == 'POSITIVE' else -1 for res in results]\n",
    "    return np.mean(scores)\n",
    "\n",
    "def preprocess_data(market_data, sentiment_score):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(market_data.values.reshape(-1, 1))\n",
    "    # Include sentiment score as a feature\n",
    "    features = np.hstack((scaled_data, np.full((scaled_data.shape[0], 1), fill_value=sentiment_score)))\n",
    "    return features[:-1], scaled_data[1:]  # X, y for model training\n",
    "\n",
    "def preprocess_for_lstm(market_data, sentiments):\n",
    "    # Assuming market_data is a DataFrame with a 'close' column\n",
    "    # and sentiments is a list of sentiment scores (-1 for negative, 0 for neutral, 1 for positive)\n",
    "    market_data['sentiment'] = sentiments[:len(market_data)]  # Truncate or pad sentiments to match market_data length\n",
    "    features = market_data[['close', 'sentiment']].values\n",
    "    return features\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def analyze_sentiment_with_bert(news):\n",
    "    sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "    return sentiment_pipeline(news)\n",
    "\n",
    "def preprocess_and_save_data(data, filename):\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_data = scaler.fit_transform(data.values.reshape(-1,1))\n",
    "#     preprocessed_df = pd.DataFrame(scaled_data, columns=['Timestamp', 'Close','High','Low','Trade_count','Open', 'Volume',' Volume Weighted Average Price'])\n",
    "#     preprocessed_df.to_csv(filename, index=False)\n",
    "#     print(f\"Data saved to {filename}\")\n",
    "#     return scaled_data\n",
    "    data.to_csv(filename, index=False)\n",
    "#     return scaled_data\n",
    "\n",
    "def main():\n",
    "    print(fetch_market_data('ES', start_date_str, end_date_str))\n",
    "    market_data = fetch_market_data('ES', start_date_str, end_date_str)\n",
    "#     tweets = fetch_tweets_about_sp500()\n",
    "#     sentiment_score = analyze_sentiment(tweets)\n",
    "#     X, y = preprocess_data(market_data, sentiment_score)\n",
    "    \n",
    "#     model = create_lstm_model((X.shape[1], X.shape[2]))\n",
    "#     model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "    print(preprocess_and_save_data(market_data, 'es500_price_history.csv'))\n",
    "\n",
    "    # Simplified decision making based on the last day's prediction\n",
    "#     last_sequence = X[-1].reshape(1, X.shape[1], X.shape[2])\n",
    "#     predicted_change = model.predict(last_sequence)\n",
    "#     decision = \"BUY\" if predicted_change > 0 else \"SELL\"\n",
    "#     print(f\"Trading decision based on model prediction: {decision}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dbb0ca61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 19:13:04.117821: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-29 19:13:04.120169: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-29 19:13:04.121514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-29 19:13:04.313302: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-29 19:13:04.314423: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-29 19:13:04.315514: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 19:13:04.706287: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-29 19:13:04.707530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-29 19:13:04.709023: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-29 19:13:04.894344: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-29 19:13:04.895704: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-29 19:13:04.896939: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-29 19:13:05.898113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-29 19:13:05.899806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-29 19:13:05.901758: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-29 19:13:06.148789: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-29 19:13:06.151289: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-29 19:13:06.152987: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - ETA: 0s - loss: 0.0392"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 19:13:08.261675: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-29 19:13:08.264336: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-29 19:13:08.265945: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-29 19:13:08.640593: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-29 19:13:08.641624: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-29 19:13:08.642945: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 264ms/step - loss: 0.0392 - val_loss: 0.0298\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0154 - val_loss: 0.0163\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0110 - val_loss: 0.0156\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0097 - val_loss: 0.0139\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0076 - val_loss: 0.0134\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0083 - val_loss: 0.0115\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0070 - val_loss: 0.0110\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0068 - val_loss: 0.0106\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0067 - val_loss: 0.0100\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0058 - val_loss: 0.0097\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0059 - val_loss: 0.0095\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0061 - val_loss: 0.0110\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0076 - val_loss: 0.0091\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0062 - val_loss: 0.0093\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0064 - val_loss: 0.0089\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0070 - val_loss: 0.0103\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0059 - val_loss: 0.0085\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0047 - val_loss: 0.0081\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0052 - val_loss: 0.0085\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0046 - val_loss: 0.0084\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.0075\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.0078\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0048 - val_loss: 0.0076\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0046 - val_loss: 0.0080\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0048 - val_loss: 0.0075\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0042 - val_loss: 0.0076\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0044 - val_loss: 0.0072\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.0072\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.0067\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0040 - val_loss: 0.0071\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.0072\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0041 - val_loss: 0.0073\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0045 - val_loss: 0.0066\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.0065\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.0065\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.0071\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0045 - val_loss: 0.0068\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0042 - val_loss: 0.0069\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0045 - val_loss: 0.0064\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0045 - val_loss: 0.0063\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.0064\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0041 - val_loss: 0.0067\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0047 - val_loss: 0.0057\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0048 - val_loss: 0.0058\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0047 - val_loss: 0.0076\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0043 - val_loss: 0.0065\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0039 - val_loss: 0.0058\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0036 - val_loss: 0.0050\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0039 - val_loss: 0.0055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 40ms/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 0.0055\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0032 - val_loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-29 19:13:26.158761: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-29 19:13:26.160712: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-29 19:13:26.162082: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-03-29 19:13:26.399694: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-03-29 19:13:26.401443: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-03-29 19:13:26.402725: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 666ms/step\n",
      "Trading decision: BUY\n"
     ]
    }
   ],
   "source": [
    "#use only LSTM model and past past history to predict price and make trading decision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Step 1: Load and preprocess the data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    close_prices = data['close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_close_prices = scaler.fit_transform(close_prices)\n",
    "    return scaled_close_prices, scaler\n",
    "\n",
    "# Create sequences from the data\n",
    "def create_sequences(data, sequence_length=60):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        x = data[i:(i + sequence_length)]\n",
    "        y = data[i + sequence_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Step 2: Define the LSTM model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(units=50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(units=50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=25),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Step 3: Train the model\n",
    "def train_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Step 4: Make a trading decision\n",
    "def make_trading_decision(model, latest_sequence_scaled, scaler):\n",
    "    predicted_price_scaled = model.predict(latest_sequence_scaled[np.newaxis, :, :])\n",
    "    predicted_price = scaler.inverse_transform(predicted_price_scaled)[0, 0]\n",
    "    latest_known_price = scaler.inverse_transform(latest_sequence_scaled[-1].reshape(-1, 1))[0, 0]\n",
    "    \n",
    "    if predicted_price > latest_known_price:\n",
    "        decision = \"BUY\"\n",
    "    elif predicted_price < latest_known_price:\n",
    "        decision = \"SELL\"\n",
    "    else:\n",
    "        decision = \"HOLD\"\n",
    "    \n",
    "    return decision\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = 'es500_price_history.csv'  # Replace this with the path to your CSV file\n",
    "    scaled_close_prices, scaler = load_and_preprocess_data(filepath)\n",
    "    X, y = create_sequences(scaled_close_prices)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = build_model((X_train.shape[1], 1))\n",
    "    train_model(model, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Example: Making a trading decision based on the latest sequence of prices\n",
    "    latest_sequence_scaled = X_test[-1]  # Assuming this is the latest available sequence\n",
    "    decision = make_trading_decision(model, latest_sequence_scaled, scaler)\n",
    "    print(f\"Trading decision: {decision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e8ede67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 11:27:50.666291: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:27:50.667407: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:27:50.668475: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:27:50.857587: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:27:50.858616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:27:50.859644: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 11:27:51.199897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:27:51.201048: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:27:51.202441: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:27:51.384467: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:27:51.385784: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:27:51.387079: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:27:52.363861: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:27:52.366147: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:27:52.368762: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:27:52.595927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:27:52.597805: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:27:52.600227: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - ETA: 0s - loss: 0.0394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 11:27:54.561678: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:27:54.563140: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:27:54.564627: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:27:54.743243: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:27:54.744285: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:27:54.745272: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 195ms/step - loss: 0.0394 - val_loss: 0.0140\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0195 - val_loss: 0.0105\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0131 - val_loss: 0.0077\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0104 - val_loss: 0.0065\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0092 - val_loss: 0.0076\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0073 - val_loss: 0.0054\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0062 - val_loss: 0.0054\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0068 - val_loss: 0.0050\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0055 - val_loss: 0.0048\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0060 - val_loss: 0.0036\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 48ms/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0038 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0034 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 11:28:11.255542: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:28:11.256551: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:28:11.258114: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:28:11.648517: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:28:11.650583: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:28:11.652765: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 846ms/step\n",
      "Decision based on current price 78.05: SELL\n"
     ]
    }
   ],
   "source": [
    "#use only LSTM model and past past history to predict price and make trading decision, with decision to hold added\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    close_prices = data['close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_close_prices = scaler.fit_transform(close_prices)\n",
    "    return scaled_close_prices, scaler\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(data, sequence_length=60):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data)-sequence_length):\n",
    "        x = data[i:(i+sequence_length)]\n",
    "        y = data[i+sequence_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Define LSTM model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(25),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Predict and decide\n",
    "def predict_and_decide(current_price, recent_prices, model, scaler):\n",
    "#     recent_prices = np.append(recent_prices, current_price).reshape(-1, 1)\n",
    "#     scaled_recent_prices = scaler.transform(recent_prices)\n",
    "    \n",
    "#     # Adjust for the sequence length expected by the model\n",
    "#     if len(scaled_recent_prices) > 60:\n",
    "#         scaled_recent_prices = scaled_recent_prices[-60:]\n",
    "#     elif len(scaled_recent_prices) < 60:\n",
    "#         scaled_recent_prices = np.pad(scaled_recent_prices, (60-len(scaled_recent_prices), 0), 'constant', constant_values=(0))\n",
    "    \n",
    "#     predicted_price_scaled = model.predict(scaled_recent_prices.T[np.newaxis, :, :])\n",
    "#     predicted_price = scaler.inverse_transform(predicted_price_scaled)[0, 0]\n",
    "    \n",
    "#     decision = \"BUY\" if predicted_price > current_price else \"SELL\" if predicted_price < current_price else \"HOLD\"\n",
    "#     return decision\n",
    "\n",
    "    # Ensure recent_prices includes the current_price and has the correct shape\n",
    "    recent_prices = np.append(recent_prices[-59:], current_price).reshape(-1, 1)\n",
    "    scaled_recent_prices = scaler.transform(recent_prices)\n",
    "    \n",
    "    # Reshape for the model: (1, sequence_length, 1)\n",
    "    scaled_recent_prices = scaled_recent_prices.reshape(1, -1, 1)\n",
    "    \n",
    "    # Predict the next day's price\n",
    "    predicted_price_scaled = model.predict(scaled_recent_prices)\n",
    "    predicted_price = scaler.inverse_transform(predicted_price_scaled)[0, 0]\n",
    "    \n",
    "    # Make a decision\n",
    "    decision = \"BUY\" if predicted_price > current_price else \"SELL\" if predicted_price < current_price else \"HOLD\"\n",
    "    return decision\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    filepath = '/Users/raymond/Desktop/CS523-Competition-1/es500_price_history.csv'  # Update with the path to your data\n",
    "    scaled_close_prices, scaler = load_and_preprocess_data(filepath)\n",
    "    X, y = create_sequences(scaled_close_prices)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Build and train model\n",
    "    model = build_model((X_train.shape[1], 1))\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "    \n",
    "    # Assuming you have a list/array of recent prices and the current price\n",
    "    recent_prices = scaled_close_prices[-59:]  # Get the last 59 prices\n",
    "    current_price = 78.05  # This would be dynamically obtained in a real scenario\n",
    "    \n",
    "    # Make decision\n",
    "    decision = predict_and_decide(current_price, recent_prices, model, scaler)\n",
    "    print(f\"Decision based on current price {current_price}: {decision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6fdc889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "# Set your API key and secret\n",
    "API_KEY = 'PKHIU3GSGREXWZOJSIP2'\n",
    "API_SECRET = 'Gi1lOxqYrvvLb3PMNEMEnqa4b0IRTbG73GZEbWVf'\n",
    "BASE_URL = 'https://paper-api.alpaca.markets'  # or 'https://api.alpaca.markets' for live trading\n",
    "\n",
    "# Initialize the API connection\n",
    "api = tradeapi.REST(API_KEY, API_SECRET, base_url=BASE_URL, api_version='v2')\n",
    "\n",
    "# Get stock data\n",
    "barset = api.get_bars('MES', '1D', limit=1)\n",
    "# aapl_bars = barset['ES']\n",
    "for bar in barset:\n",
    "    print(bar.t, bar.o, bar.h, bar.l, bar.c, bar.v)\n",
    "    current_price = bar.c\n",
    "    print(\"close price\", bar.c)\n",
    "    \n",
    "# decision = predict_and_decide(current_price, recent_prices, model, scaler)\n",
    "# print(f\"Decision based on current price {current_price}: {decision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38cb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5434912",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://api.marketaux.com/v1/sentiment?api_token=EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj&languages=en&query=S%26P+500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sentiment_score\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Fetch and print the sentiment score for S&P 500-related news\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m sp500_sentiment_score \u001b[38;5;241m=\u001b[39m \u001b[43mget_sp500_sentiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mS&P 500 Sentiment Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msp500_sentiment_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m, in \u001b[0;36mget_sp500_sentiment\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.marketaux.com/v1/sentiment?\u001b[39m\u001b[38;5;132;01m{\u001b[39;00murlencode(params)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Hypothetical endpoint for sentiment\u001b[39;00m\n\u001b[1;32m     15\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m json_response \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Assuming the API response contains a sentiment score for the query\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.marketaux.com/v1/sentiment?api_token=EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj&languages=en&query=S%26P+500"
     ]
    }
   ],
   "source": [
    "#sentiment analysis using fetched marketaux headline\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "API_TOKEN = \"EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj\"\n",
    "languages = [\"en\"]\n",
    "\n",
    "def get_sp500_sentiment():\n",
    "    params = {\n",
    "        \"api_token\": API_TOKEN,\n",
    "        \"languages\": \",\".join(languages),\n",
    "        \"query\": \"S&P 500\",  # Assuming 'query' parameter can be used to filter news by keywords\n",
    "    }\n",
    "    url = f\"https://api.marketaux.com/v1/sentiment?{urlencode(params)}\"  # Hypothetical endpoint for sentiment\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    json_response = response.json()\n",
    "    \n",
    "    # Assuming the API response contains a sentiment score for the query\n",
    "    sentiment_score = json_response.get(\"sentiment_score\")\n",
    "    return sentiment_score\n",
    "\n",
    "# Fetch and print the sentiment score for S&P 500-related news\n",
    "sp500_sentiment_score = get_sp500_sentiment()\n",
    "print(f\"S&P 500 Sentiment Score: {sp500_sentiment_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76da6644",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 11:38:59.446578: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:38:59.447597: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:38:59.448879: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:38:59.618724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:38:59.619702: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:38:59.620723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 11:38:59.906666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:38:59.907908: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:38:59.909104: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:39:00.107121: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:39:00.108392: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:39:00.109879: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:39:01.096010: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:39:01.097113: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:39:01.098478: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:39:01.279703: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:39:01.280947: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:39:01.281989: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - ETA: 0s - loss: 0.1065"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 11:39:03.086216: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:39:03.087232: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:39:03.088542: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:39:03.259348: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:39:03.260376: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:39:03.261760: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 4s 192ms/step - loss: 0.1065 - val_loss: 0.0193\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0202 - val_loss: 0.0189\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 44ms/step - loss: 0.0196 - val_loss: 0.0137\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 49ms/step - loss: 0.0143 - val_loss: 0.0161\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0133 - val_loss: 0.0111\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0088 - val_loss: 0.0080\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0088 - val_loss: 0.0068\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0068 - val_loss: 0.0063\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0067 - val_loss: 0.0052\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0075 - val_loss: 0.0055\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0073 - val_loss: 0.0056\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0053 - val_loss: 0.0047\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0045 - val_loss: 0.0057\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 33ms/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0054 - val_loss: 0.0025\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 35ms/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 34ms/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 32ms/step - loss: 0.0038 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 31ms/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 87/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 29ms/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 36ms/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 39ms/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 37ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 38ms/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 30ms/step - loss: 0.0036 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-02 11:39:19.632903: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:39:19.633874: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:39:19.635850: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-04-02 11:39:19.796270: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-04-02 11:39:19.797668: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-04-02 11:39:19.798779: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 526ms/step\n",
      "Decision: SELL | Shares: 50 | Current Profit: $202.50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    close_prices = data['close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_close_prices = scaler.fit_transform(close_prices)\n",
    "    return scaled_close_prices, scaler\n",
    "\n",
    "# Create sequences for LSTM training\n",
    "def create_sequences(data, sequence_length=60):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        x = data[i:(i + sequence_length)]\n",
    "        y = data[i + sequence_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Define LSTM model structure\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(25),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Predict next day's price and make a decision\n",
    "def predict_and_decide(current_price, recent_prices, model, scaler, available_funds, current_shares, total_cost, transaction_fee=0):\n",
    "    # Ensure recent_prices includes the current_price and has the correct shape\n",
    "    recent_prices = np.append(recent_prices[-59:], current_price).reshape(-1, 1)\n",
    "    scaled_recent_prices = scaler.transform(recent_prices)\n",
    "    scaled_recent_prices = scaled_recent_prices.reshape(1, -1, 1)\n",
    "    \n",
    "    # Predict the next day's price\n",
    "    predicted_price_scaled = model.predict(scaled_recent_prices)\n",
    "    predicted_price = scaler.inverse_transform(predicted_price_scaled)[0, 0]\n",
    "    \n",
    "    # Calculate current profit\n",
    "    current_profit = (current_price * current_shares) - total_cost\n",
    "    predicted_profit = (predicted_price * current_shares) - total_cost\n",
    "    \n",
    "    # Decision logic\n",
    "    if predicted_price > current_price and predicted_profit > current_profit:\n",
    "        # Buy if predicted profit is greater than current profit\n",
    "        max_affordable_shares = int((available_funds - transaction_fee) / current_price)\n",
    "        decision = \"BUY\", max_affordable_shares\n",
    "    elif predicted_price < current_price and current_profit > 0:\n",
    "        # Sell if current profit is positive and predicted price is less than current\n",
    "        decision = \"SELL\", current_shares\n",
    "    else:\n",
    "        # Hold if no clear profitable action\n",
    "        decision = \"HOLD\", 0\n",
    "    \n",
    "    return decision, current_profit\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    filepath = '/Users/raymond/Desktop/CS523-Competition-1/es500_price_history.csv'  # Replace with your actual data file path\n",
    "    scaled_close_prices, scaler = load_and_preprocess_data(filepath)\n",
    "    X, y = create_sequences(scaled_close_prices)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Build and train the LSTM model\n",
    "    model = build_model((X_train.shape[1], 1))\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "    \n",
    "    # Example parameters for trading decision\n",
    "    available_funds = 10000  # Example available funds in dollars\n",
    "    current_price = 78.05  # Current price of the stock, to be dynamically obtained\n",
    "    recent_prices = scaled_close_prices[-60:-1]  # Last 59 prices plus current for the model input\n",
    "    current_shares = 50  # Current number of shares held\n",
    "    total_cost = 3700  # Total cost of current shares held\n",
    "    \n",
    "    # Make a decision based on current scenario\n",
    "    decision, current_profit = predict_and_decide(current_price, recent_prices, model, scaler, available_funds, current_shares, total_cost)\n",
    "    print(f\"Decision: {decision[0]} | Shares: {decision[1]} | Current Profit: ${current_profit:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "03b1f6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account Balance: 856736.50\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "Decision: SELL | Shares: 50 | Current Profit: $202.50\n"
     ]
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "\n",
    "# Assuming 'ib' is already connected and is an instance of ib_insync.IB()\n",
    "\n",
    "# Use the asynchronous version of the accountSummary function with await\n",
    "account_summary = await ib.accountSummaryAsync()\n",
    "\n",
    "# Find the total cash balance\n",
    "balance = next((item for item in account_summary if item.tag == 'TotalCashBalance'), None)\n",
    "print(\"Account Balance:\", balance.value if balance else \"No balance found\")\n",
    "available_funds = balance.value\n",
    "decision, current_profit = predict_and_decide(current_price, recent_prices, model, scaler, available_funds, current_shares, total_cost)\n",
    "print(f\"Decision: {decision[0]} | Shares: {decision[1]} | Current Profit: ${current_profit:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0714a829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a89ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
