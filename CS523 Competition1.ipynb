{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b52dcf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ib_insync in c:\\users\\15596\\anaconda3\\lib\\site-packages (0.9.86)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: eventkit in c:\\users\\15596\\anaconda3\\lib\\site-packages (from ib_insync) (1.0.3)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\15596\\anaconda3\\lib\\site-packages (from ib_insync) (1.5.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\15596\\anaconda3\\lib\\site-packages (from eventkit->ib_insync) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "pip install ib_insync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3d0e77e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Interactive Brokers\n"
     ]
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "\n",
    "# Utilize an instance of IB\n",
    "ib = IB()\n",
    "\n",
    "# Connect to the IB server using await in front of the connectAsync method\n",
    "try:\n",
    "    await ib.connectAsync('127.0.0.1', 7497, clientId=1)\n",
    "    print(\"Connected to Interactive Brokers\")\n",
    "except RuntimeError as e:\n",
    "    print(f\"Runtime Error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "# from ib_insync import *\n",
    "\n",
    "# ib = IB()\n",
    "# ib.connect('127.0.0.1', 7497, clientId=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c16b32cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "contract = Future('ES', '202406', 'CME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f5088c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Future(conId=551601561, symbol='ES', lastTradeDateOrContractMonth='20240621', multiplier='50', exchange='CME', currency='USD', localSymbol='ESM4', tradingClass='ES')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await ib.qualifyContractsAsync(contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d12b14ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(ib.reqMarketDataType(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41f7d38f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ib_insync import *\n",
    "\n",
    "# Assume 'ib' is already connected and is an instance of ib_insync.IB()\n",
    "# Also assume 'contract' has been created and is a valid ib_insync.Contract object\n",
    "\n",
    "# Use the asynchronous version of the method with await\n",
    "try:\n",
    "    historical_data = await ib.reqHistoricalDataAsync(\n",
    "        contract, endDateTime='', durationStr='30 D',\n",
    "        barSizeSetting='1 hour', whatToShow='MIDPOINT', useRTH=True\n",
    "    )\n",
    "    \n",
    "    # Proceed with the historical data\n",
    "#     for bar in historical_data:\n",
    "#         print(bar)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38ef5a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         date     open     high      low    close  volume  \\\n",
      "0   2024-03-14 09:30:00-04:00  5240.00  5241.50  5208.75  5209.50    -1.0   \n",
      "1   2024-03-14 10:00:00-04:00  5209.50  5226.00  5203.00  5216.25    -1.0   \n",
      "2   2024-03-14 11:00:00-04:00  5216.25  5224.00  5210.25  5220.00    -1.0   \n",
      "3   2024-03-14 12:00:00-04:00  5220.00  5221.75  5208.00  5208.75    -1.0   \n",
      "4   2024-03-14 13:00:00-04:00  5208.75  5216.00  5196.75  5215.25    -1.0   \n",
      "..                        ...      ...      ...      ...      ...     ...   \n",
      "235 2024-04-25 12:00:00-04:00  5050.25  5068.25  5046.50  5065.50    -1.0   \n",
      "236 2024-04-25 13:00:00-04:00  5065.50  5086.50  5057.25  5083.25    -1.0   \n",
      "237 2024-04-25 14:00:00-04:00  5083.25  5085.25  5064.50  5072.75    -1.0   \n",
      "238 2024-04-25 15:00:00-04:00  5072.75  5090.75  5072.00  5082.75    -1.0   \n",
      "239 2024-04-25 16:00:00-04:00  5082.75  5131.75  5079.00  5125.25    -1.0   \n",
      "\n",
      "     average  barCount  \n",
      "0       -1.0        -1  \n",
      "1       -1.0        -1  \n",
      "2       -1.0        -1  \n",
      "3       -1.0        -1  \n",
      "4       -1.0        -1  \n",
      "..       ...       ...  \n",
      "235     -1.0        -1  \n",
      "236     -1.0        -1  \n",
      "237     -1.0        -1  \n",
      "238     -1.0        -1  \n",
      "239     -1.0        -1  \n",
      "\n",
      "[240 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pytz\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'historical_data' contains the historical data returned by reqHistoricalDataAsync\n",
    "\n",
    "# Convert timestamps to the desired time zone (e.g., 'US/Eastern')\n",
    "tz = pytz.timezone('US/Eastern')\n",
    "for bar in historical_data:\n",
    "    bar.date = bar.date.astimezone(tz)\n",
    "\n",
    "# Convert historical data to DataFrame\n",
    "df = pd.DataFrame([vars(bar) for bar in historical_data])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a0d65e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         date     open     high      low    close  volume  \\\n",
      "0   2024-03-14 09:30:00-04:00  5240.00  5241.50  5208.75  5209.50    -1.0   \n",
      "1   2024-03-14 10:00:00-04:00  5209.50  5226.00  5203.00  5216.25    -1.0   \n",
      "2   2024-03-14 11:00:00-04:00  5216.25  5224.00  5210.25  5220.00    -1.0   \n",
      "3   2024-03-14 12:00:00-04:00  5220.00  5221.75  5208.00  5208.75    -1.0   \n",
      "4   2024-03-14 13:00:00-04:00  5208.75  5216.00  5196.75  5215.25    -1.0   \n",
      "..                        ...      ...      ...      ...      ...     ...   \n",
      "235 2024-04-25 12:00:00-04:00  5050.25  5068.25  5046.50  5065.50    -1.0   \n",
      "236 2024-04-25 13:00:00-04:00  5065.50  5086.50  5057.25  5083.25    -1.0   \n",
      "237 2024-04-25 14:00:00-04:00  5083.25  5085.25  5064.50  5072.75    -1.0   \n",
      "238 2024-04-25 15:00:00-04:00  5072.75  5090.75  5072.00  5082.75    -1.0   \n",
      "239 2024-04-25 16:00:00-04:00  5082.75  5131.75  5079.00  5125.25    -1.0   \n",
      "\n",
      "     average  barCount  \n",
      "0       -1.0        -1  \n",
      "1       -1.0        -1  \n",
      "2       -1.0        -1  \n",
      "3       -1.0        -1  \n",
      "4       -1.0        -1  \n",
      "..       ...       ...  \n",
      "235     -1.0        -1  \n",
      "236     -1.0        -1  \n",
      "237     -1.0        -1  \n",
      "238     -1.0        -1  \n",
      "239     -1.0        -1  \n",
      "\n",
      "[240 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "df = util.df(historical_data)\n",
    "print(df)\n",
    "def preprocess_and_save_data(data, filename):\n",
    "    data.to_csv(filename, index=False)\n",
    "preprocess_and_save_data(df, 'ib_es500_price_history.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7eaf9fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = Order(action='SELL', totalQuantity=5, orderType='LMT', lmtPrice=5300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9790a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "trade = ib.placeOrder(contract, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88e729c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "order = Order(action='BUY', totalQuantity=9, orderType='LMT', lmtPrice=5070)\n",
    "trade = ib.placeOrder(contract, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "241072c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account Balance: 1081472.3617\n"
     ]
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "\n",
    "# Assuming 'ib' is already connected and is an instance of ib_insync.IB()\n",
    "\n",
    "# Use the asynchronous version of the accountSummary function with await\n",
    "account_summary = await ib.accountSummaryAsync()\n",
    "\n",
    "# Find the total cash balance\n",
    "balance = next((item for item in account_summary if item.tag == 'TotalCashBalance'), None)\n",
    "print(\"Account Balance:\", balance.value if balance else \"No balance found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d6012e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1081472.3617\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "def buy(tq, ot, lp):\n",
    "    order = Order(action='BUY', totalQuantity=tq, orderType=ot, lmtPrice=lp)\n",
    "    trade = ib.placeOrder(contract, order)\n",
    "def sell(tq, ot, lp):\n",
    "    order = Order(action='SELL', totalQuantity=tq, orderType=ot, lmtPrice=lp)\n",
    "    trade = ib.placeOrder(contract, order)  \n",
    "\n",
    "\n",
    "async def check_total_cash_balance():\n",
    "    try:\n",
    "        account_summary = await ib.accountSummaryAsync()\n",
    "        balance = next((item for item in account_summary if item.tag == 'TotalCashBalance'), None)\n",
    "        return balance.value  # Assuming 'balance' has a 'value' attribute.\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "# Async function to call and print the result of check_total_cash_balance\n",
    "async def main():\n",
    "    balance = await check_total_cash_balance()\n",
    "    print(balance)\n",
    "\n",
    "# Running the main function\n",
    "if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())\n",
    "    await main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b6ca3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b1278ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alpaca-trade-api\n",
      "  Obtaining dependency information for alpaca-trade-api from https://files.pythonhosted.org/packages/0b/b2/4557d0a4c837b020bc5c8971e8fde8b976e332d5c225476699e0b5e30b41/alpaca_trade_api-3.2.0-py3-none-any.whl.metadata\n",
      "  Downloading alpaca_trade_api-3.2.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: pandas>=0.18.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpaca-trade-api) (2.0.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpaca-trade-api) (1.22.2)\n",
      "Requirement already satisfied: requests<3,>2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpaca-trade-api) (2.31.0)\n",
      "Requirement already satisfied: urllib3<2,>1.24 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpaca-trade-api) (1.26.16)\n",
      "Requirement already satisfied: websocket-client<2,>=0.56.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpaca-trade-api) (1.5.3)\n",
      "Collecting websockets<11,>=9.0 (from alpaca-trade-api)\n",
      "  Obtaining dependency information for websockets<11,>=9.0 from https://files.pythonhosted.org/packages/47/4d/f2e28f112302d3bc794b74ae64656255161d8223f4d47bd17d40cbb3629e/websockets-10.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading websockets-10.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting msgpack==1.0.3 (from alpaca-trade-api)\n",
      "  Obtaining dependency information for msgpack==1.0.3 from https://files.pythonhosted.org/packages/3a/57/c90cb0b1ab68650ff0068240449bc17c269069bd898cf283dc8db72e8788/msgpack-1.0.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading msgpack-1.0.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (8.7 kB)\n",
      "Collecting aiohttp<4,>=3.8.3 (from alpaca-trade-api)\n",
      "  Obtaining dependency information for aiohttp<4,>=3.8.3 from https://files.pythonhosted.org/packages/20/1c/b7e668a1583cbb1e5060b45baee68a50123f66470ac463f81f7e3b3c3bab/aiohttp-3.9.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading aiohttp-3.9.3-cp39-cp39-macosx_10_9_x86_64.whl.metadata (7.4 kB)\n",
      "Collecting PyYAML==6.0.1 (from alpaca-trade-api)\n",
      "  Obtaining dependency information for PyYAML==6.0.1 from https://files.pythonhosted.org/packages/57/c5/5d09b66b41d549914802f482a2118d925d876dc2a35b2d127694c1345c34/PyYAML-6.0.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading PyYAML-6.0.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting deprecation==2.1.0 (from alpaca-trade-api)\n",
      "  Obtaining dependency information for deprecation==2.1.0 from https://files.pythonhosted.org/packages/02/c3/253a89ee03fc9b9682f1541728eb66db7db22148cd94f89ab22528cd1e1b/deprecation-2.1.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from deprecation==2.1.0->alpaca-trade-api) (21.3)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
      "  Obtaining dependency information for aiosignal>=1.1.2 from https://files.pythonhosted.org/packages/76/ac/a7305707cb852b7e16ff80eaf5692309bde30e2b1100a1fcacdc8f731d97/aiosignal-1.3.1-py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp<4,>=3.8.3->alpaca-trade-api) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/4d/23/7f01123d0e5adcc65cbbde5731378237dea7db467abd19e391f1ddd4130d/frozenlist-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/7d/5c/c364a77b37f580cc28da4194b77ed04286c7631933d3e64fdae40f1972e2/multidict-6.0.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading multidict-6.0.5-cp39-cp39-macosx_10_9_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.0 from https://files.pythonhosted.org/packages/8f/0f/9fa6f044b04267d22ec29df23936ffd4bf4572ccecd889c6b2b1761c2c5c/yarl-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata\n",
      "  Downloading yarl-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl.metadata (31 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp<4,>=3.8.3->alpaca-trade-api)\n",
      "  Obtaining dependency information for async-timeout<5.0,>=4.0 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=0.18.1->alpaca-trade-api) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=0.18.1->alpaca-trade-api) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from pandas>=0.18.1->alpaca-trade-api) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>2->alpaca-trade-api) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>2->alpaca-trade-api) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>2->alpaca-trade-api) (2023.5.7)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=0.18.1->alpaca-trade-api) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging->deprecation==2.1.0->alpaca-trade-api) (3.0.7)\n",
      "Downloading alpaca_trade_api-3.2.0-py3-none-any.whl (34 kB)\n",
      "Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading msgpack-1.0.3-cp39-cp39-macosx_10_9_x86_64.whl (75 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.1-cp39-cp39-macosx_10_9_x86_64.whl (197 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.8/197.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.3-cp39-cp39-macosx_10_9_x86_64.whl (398 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m398.8/398.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading websockets-10.4-cp39-cp39-macosx_10_9_x86_64.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-macosx_10_9_x86_64.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multidict-6.0.5-cp39-cp39-macosx_10_9_x86_64.whl (30 kB)\n",
      "Downloading yarl-1.9.4-cp39-cp39-macosx_10_9_x86_64.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.7/83.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: msgpack, websockets, PyYAML, multidict, frozenlist, async-timeout, yarl, deprecation, aiosignal, aiohttp, alpaca-trade-api\n",
      "  Attempting uninstall: PyYAML\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed PyYAML-6.0.1 aiohttp-3.9.3 aiosignal-1.3.1 alpaca-trade-api-3.2.0 async-timeout-4.0.3 deprecation-2.1.0 frozenlist-1.4.1 msgpack-1.0.3 multidict-6.0.5 websockets-10.4 yarl-1.9.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install alpaca-trade-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cad39757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "Not connected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m order \u001b[38;5;241m=\u001b[39m Order(action\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBUY\u001b[39m\u001b[38;5;124m'\u001b[39m, totalQuantity\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, orderType\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLMT\u001b[39m\u001b[38;5;124m'\u001b[39m, lmtPrice\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5200\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m trade \u001b[38;5;241m=\u001b[39m \u001b[43mib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplaceOrder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontract\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ib_insync/ib.py:654\u001b[0m, in \u001b[0;36mIB.placeOrder\u001b[0;34m(self, contract, order)\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplaceOrder\u001b[39m(\u001b[38;5;28mself\u001b[39m, contract: Contract, order: Order) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Trade:\n\u001b[1;32m    645\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;124;03m    Place a new order or modify an existing order.\u001b[39;00m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;124;03m    Returns a Trade that is kept live updated with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[38;5;124;03m        order: The order to be placed.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 654\u001b[0m     orderId \u001b[38;5;241m=\u001b[39m order\u001b[38;5;241m.\u001b[39morderId \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetReqId\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mplaceOrder(orderId, contract, order)\n\u001b[1;32m    656\u001b[0m     now \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mnow(datetime\u001b[38;5;241m.\u001b[39mtimezone\u001b[38;5;241m.\u001b[39mutc)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/ib_insync/client.py:160\u001b[0m, in \u001b[0;36mClient.getReqId\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get new request ID.\"\"\"\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misReady():\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot connected\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    161\u001b[0m newId \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reqIdSeq\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reqIdSeq \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mConnectionError\u001b[0m: Not connected"
     ]
    }
   ],
   "source": [
    "order = Order(action='BUY', totalQuantity=100, orderType='LMT', lmtPrice=5200)\n",
    "trade = ib.placeOrder(contract, order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9286490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (24.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a92a535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-12 00:00:00-04:00 59.35 59.495 58.43 58.79 2204619\n",
      "close price 58.79\n"
     ]
    }
   ],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "# Set your API key and secret\n",
    "API_KEY = 'PKHIU3GSGREXWZOJSIP2'\n",
    "API_SECRET = 'Gi1lOxqYrvvLb3PMNEMEnqa4b0IRTbG73GZEbWVf'\n",
    "BASE_URL = 'https://paper-api.alpaca.markets'  # or 'https://api.alpaca.markets' for live trading\n",
    "\n",
    "# Initialize the API connection\n",
    "api = tradeapi.REST(API_KEY, API_SECRET, base_url=BASE_URL, api_version='v2')\n",
    "\n",
    "# Get stock data\n",
    "barset = api.get_bars('ES', '1D', limit=10)\n",
    "# aapl_bars = barset['AAPL']\n",
    "for bar in barset:\n",
    "    print(bar.t, bar.o, bar.h, bar.l, bar.c, bar.v)\n",
    "    print(\"close price\", bar.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af4494af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data for AAPL:\n",
      "Timestamp: 2024-03-04 00:00:00-05:00\n",
      "Open: 176.15\n",
      "High: 176.9\n",
      "Low: 173.79\n",
      "Close: 175.1\n",
      "Volume: 81510101\n",
      "\n",
      "Timestamp: 2024-03-05 00:00:00-05:00\n",
      "Open: 170.76\n",
      "High: 172.04\n",
      "Low: 169.62\n",
      "Close: 170.12\n",
      "Volume: 95432355\n",
      "\n",
      "Timestamp: 2024-03-06 00:00:00-05:00\n",
      "Open: 171.06\n",
      "High: 171.24\n",
      "Low: 168.68\n",
      "Close: 169.12\n",
      "Volume: 68587707\n",
      "\n",
      "Timestamp: 2024-03-07 00:00:00-05:00\n",
      "Open: 169.15\n",
      "High: 170.73\n",
      "Low: 168.49\n",
      "Close: 169\n",
      "Volume: 71765061\n",
      "\n",
      "Timestamp: 2024-03-08 00:00:00-05:00\n",
      "Open: 169\n",
      "High: 173.7\n",
      "Low: 168.94\n",
      "Close: 170.73\n",
      "Volume: 76159346\n",
      "\n",
      "Timestamp: 2024-03-11 00:00:00-04:00\n",
      "Open: 172.94\n",
      "High: 174.38\n",
      "Low: 172.05\n",
      "Close: 172.75\n",
      "Volume: 60139473\n",
      "\n",
      "Timestamp: 2024-03-12 00:00:00-04:00\n",
      "Open: 173.15\n",
      "High: 174.03\n",
      "Low: 171.01\n",
      "Close: 173.23\n",
      "Volume: 59825372\n",
      "\n",
      "Timestamp: 2024-03-13 00:00:00-04:00\n",
      "Open: 172.77\n",
      "High: 173.185\n",
      "Low: 170.76\n",
      "Close: 171.13\n",
      "Volume: 52488692\n",
      "\n",
      "Timestamp: 2024-03-14 00:00:00-04:00\n",
      "Open: 172.91\n",
      "High: 174.3078\n",
      "Low: 172.05\n",
      "Close: 173\n",
      "Volume: 72913507\n",
      "\n",
      "Timestamp: 2024-03-15 00:00:00-04:00\n",
      "Open: 171.17\n",
      "High: 172.62\n",
      "Low: 170.285\n",
      "Close: 172.62\n",
      "Volume: 121752699\n",
      "\n",
      "Timestamp: 2024-03-18 00:00:00-04:00\n",
      "Open: 175.57\n",
      "High: 177.71\n",
      "Low: 173.52\n",
      "Close: 173.72\n",
      "Volume: 75604184\n",
      "\n",
      "Timestamp: 2024-03-19 00:00:00-04:00\n",
      "Open: 174.34\n",
      "High: 176.605\n",
      "Low: 173.03\n",
      "Close: 176.08\n",
      "Volume: 55215244\n",
      "\n",
      "Timestamp: 2024-03-20 00:00:00-04:00\n",
      "Open: 175.72\n",
      "High: 178.67\n",
      "Low: 175.09\n",
      "Close: 178.67\n",
      "Volume: 53423102\n",
      "\n",
      "Timestamp: 2024-03-21 00:00:00-04:00\n",
      "Open: 177.05\n",
      "High: 177.49\n",
      "Low: 170.84\n",
      "Close: 171.37\n",
      "Volume: 106181270\n",
      "\n",
      "Timestamp: 2024-03-22 00:00:00-04:00\n",
      "Open: 171.76\n",
      "High: 173.05\n",
      "Low: 170.06\n",
      "Close: 172.28\n",
      "Volume: 71160138\n",
      "\n",
      "Timestamp: 2024-03-25 00:00:00-04:00\n",
      "Open: 170.565\n",
      "High: 171.94\n",
      "Low: 169.45\n",
      "Close: 170.85\n",
      "Volume: 54288328\n",
      "\n",
      "Timestamp: 2024-03-26 00:00:00-04:00\n",
      "Open: 170\n",
      "High: 171.42\n",
      "Low: 169.58\n",
      "Close: 169.71\n",
      "Volume: 57388449\n",
      "\n",
      "Timestamp: 2024-03-27 00:00:00-04:00\n",
      "Open: 170.41\n",
      "High: 173.6\n",
      "Low: 170.11\n",
      "Close: 173.31\n",
      "Volume: 60273265\n",
      "\n",
      "Timestamp: 2024-03-28 00:00:00-04:00\n",
      "Open: 171.75\n",
      "High: 172.23\n",
      "Low: 170.51\n",
      "Close: 171.48\n",
      "Volume: 65672690\n",
      "\n",
      "Timestamp: 2024-04-01 00:00:00-04:00\n",
      "Open: 171.19\n",
      "High: 171.25\n",
      "Low: 169.475\n",
      "Close: 170.03\n",
      "Volume: 46240500\n",
      "\n",
      "Timestamp: 2024-04-02 00:00:00-04:00\n",
      "Open: 169.08\n",
      "High: 169.34\n",
      "Low: 168.2302\n",
      "Close: 168.84\n",
      "Volume: 49356481\n",
      "\n",
      "Timestamp: 2024-04-03 00:00:00-04:00\n",
      "Open: 168.79\n",
      "High: 170.68\n",
      "Low: 168.58\n",
      "Close: 169.65\n",
      "Volume: 47691715\n",
      "\n",
      "Timestamp: 2024-04-04 00:00:00-04:00\n",
      "Open: 170.29\n",
      "High: 171.92\n",
      "Low: 168.82\n",
      "Close: 168.82\n",
      "Volume: 53704386\n",
      "\n",
      "Timestamp: 2024-04-05 00:00:00-04:00\n",
      "Open: 169.59\n",
      "High: 170.39\n",
      "Low: 168.95\n",
      "Close: 169.58\n",
      "Volume: 42104826\n",
      "\n",
      "Timestamp: 2024-04-08 00:00:00-04:00\n",
      "Open: 169.03\n",
      "High: 169.2\n",
      "Low: 168.24\n",
      "Close: 168.45\n",
      "Volume: 37425513\n",
      "\n",
      "Timestamp: 2024-04-09 00:00:00-04:00\n",
      "Open: 168.7\n",
      "High: 170.08\n",
      "Low: 168.35\n",
      "Close: 169.67\n",
      "Volume: 42451209\n",
      "\n",
      "Timestamp: 2024-04-10 00:00:00-04:00\n",
      "Open: 168.8\n",
      "High: 169.09\n",
      "Low: 167.11\n",
      "Close: 167.78\n",
      "Volume: 49709336\n",
      "\n",
      "Timestamp: 2024-04-11 00:00:00-04:00\n",
      "Open: 168.34\n",
      "High: 175.46\n",
      "Low: 168.16\n",
      "Close: 175.04\n",
      "Volume: 91070275\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "try:\n",
    "    # Calculate the start and end dates for the last 5 days\n",
    "    end_date = datetime.today() - timedelta(days=1)  # Fetch data until yesterday\n",
    "    start_date = end_date - timedelta(days=40)  # Fetch data from 5 days ago\n",
    "\n",
    "    # Format dates in ISO 8601 format (YYYY-MM-DD)\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Define the symbols, timeframe, and limit\n",
    "    symbols = ['AAPL']  # Add more symbols as needed\n",
    "    timeframe = '1D'  # Daily bars\n",
    "    limit = 40  # Number of bars to fetch, fetch data for the last 5 days\n",
    "\n",
    "    # Create an empty dictionary to store historical data for each symbol\n",
    "    historical_data = {}\n",
    "\n",
    "    # Fetch historical data for each symbol\n",
    "    for symbol in symbols:\n",
    "        barset = api.get_bars(symbol, timeframe, start=start_date_str, end=end_date_str, limit=limit)\n",
    "\n",
    "        # Store the BarSet object in the dictionary\n",
    "        historical_data[symbol] = barset\n",
    "\n",
    "    # Print the fetched data for each symbol\n",
    "    for symbol, barset in historical_data.items():\n",
    "        print(f\"Data for {symbol}:\")\n",
    "        for bar in barset:\n",
    "            print(\"Timestamp:\", bar.t)\n",
    "            print(\"Open:\", bar.o)\n",
    "            print(\"High:\", bar.h)\n",
    "            print(\"Low:\", bar.l)\n",
    "            print(\"Close:\", bar.c)\n",
    "            print(\"Volume:\", bar.v)\n",
    "            print()  # Add a newline for clarity between bars\n",
    "        print()  # Add an extra newline for clarity between symbols\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "705642a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting alpha_vantage\n",
      "  Obtaining dependency information for alpha_vantage from https://files.pythonhosted.org/packages/ba/b4/d95f9e0eccea6732bab5a079772d453a4f0b68a9f63740d9cf320f92beaa/alpha_vantage-2.3.1-py3-none-any.whl.metadata\n",
      "  Downloading alpha_vantage-2.3.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: aiohttp in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpha_vantage) (3.9.3)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from alpha_vantage) (2.31.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from aiohttp->alpha_vantage) (4.0.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->alpha_vantage) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->alpha_vantage) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->alpha_vantage) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->alpha_vantage) (2023.5.7)\n",
      "Downloading alpha_vantage-2.3.1-py3-none-any.whl (31 kB)\n",
      "Installing collected packages: alpha_vantage\n",
      "Successfully installed alpha_vantage-2.3.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install alpha_vantage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b029a376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            1. open  2. high  3. low  4. close  5. volume\n",
      "date                                                     \n",
      "2024-04-01    59.71   59.710  58.525     58.88  1503051.0\n",
      "2024-03-28    59.27   59.985  58.800     59.77  1921036.0\n",
      "2024-03-27    56.91   58.990  56.910     58.98  2840904.0\n",
      "2024-03-26    57.49   57.820  56.160     56.29  2165646.0\n",
      "2024-03-25    57.89   58.250  57.190     57.52  1923841.0\n",
      "...             ...      ...     ...       ...        ...\n",
      "2023-11-10    54.57   54.750  53.625     53.80  2398277.0\n",
      "2023-11-09    55.97   56.130  54.210     54.24  2427103.0\n",
      "2023-11-08    56.17   56.340  54.900     55.69  2249165.0\n",
      "2023-11-07    56.37   57.640  55.630     56.35  3137947.0\n",
      "2023-11-06    54.83   56.610  54.690     56.56  5270655.0\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "# Set your API key\n",
    "API_KEY = 'your_api_key'\n",
    "\n",
    "# Initialize the API connection\n",
    "ts = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "\n",
    "# Get stock data\n",
    "data, metadata = ts.get_daily(symbol='ES', outputsize='compact')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7ee2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Set the URL for MarketAux\n",
    "url = 'https://www.marketaux.com/'\n",
    "\n",
    "try:\n",
    "    # Send a request to the website and parse the HTML content\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Raise an error for bad status codes\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Extract financial headlines\n",
    "    headlines = soup.find_all('h2', class_='entry-title')\n",
    "    for headline in headlines:\n",
    "        print(headline.text)\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"An error occurred:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f5c87c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'error': {'code': 'invalid_api_token', 'message': 'An invalid API token was supplied.'}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 37\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[38;5;66;03m# Append the article's title to the list of headlines for this date\u001b[39;00m\n\u001b[1;32m     36\u001b[0m         headlines[date_str]\u001b[38;5;241m.\u001b[39mappend(article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 37\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mget_headlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m extract_headlines(data)\n",
      "Cell \u001b[0;32mIn[15], line 12\u001b[0m, in \u001b[0;36mget_headlines\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m news_headlines \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(news_headlines)  \u001b[38;5;66;03m# Print the response content\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m article \u001b[38;5;129;01min\u001b[39;00m \u001b[43mnews_headlines\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     13\u001b[0m     date \u001b[38;5;241m=\u001b[39m article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpublished_at\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     14\u001b[0m     title \u001b[38;5;241m=\u001b[39m article[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dateutil.parser import parse\n",
    "\n",
    "def get_headlines():\n",
    "    url = \"https://api.marketaux.com/v1/news/all?symbols=^GSPC&filter_entities=true&language=en&api_token=\"\n",
    "    \n",
    "    cleaned_data = []\n",
    "    for _ in range(3):\n",
    "        response = requests.get(url)\n",
    "        news_headlines = response.json()\n",
    "        print(news_headlines)  # Print the response content\n",
    "        for article in news_headlines['data']:\n",
    "            date = article['published_at']\n",
    "            title = article['title']\n",
    "            cleaned_data.append({'date': date, 'headline': title})\n",
    "    \n",
    "    return cleaned_data\n",
    "\n",
    "def extract_headlines(data):\n",
    "    # Initialize an empty dictionary to hold the headlines\n",
    "    headlines = {}\n",
    "    \n",
    "    # Loop through each article in the data file\n",
    "    for article in data['articles']:\n",
    "        # Extract the date from the 'publishedAt' field and convert it to a datetime object\n",
    "        date = parse(article['publishedAt']).date()\n",
    "        \n",
    "        # Convert the date to a string in the format 'YYYY-MM-DD'\n",
    "        date_str = date.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # If the date is not already in the headlines dictionary, add it with an empty list as the value\n",
    "        if date_str not in headlines:\n",
    "            headlines[date_str] = []\n",
    "        \n",
    "        # Append the article's title to the list of headlines for this date\n",
    "        headlines[date_str].append(article['title'])\n",
    "data = get_headlines()\n",
    "extract_headlines(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "563fc0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Information\n",
      "2. Symbol\n",
      "3. Last Refreshed\n",
      "4. Output Size\n",
      "5. Time Zone\n"
     ]
    }
   ],
   "source": [
    "from alpha_vantage.timeseries import TimeSeries\n",
    "\n",
    "# Set your API key\n",
    "API_KEY = 'your_api_key'\n",
    "\n",
    "# Initialize the API connection\n",
    "ts = TimeSeries(key=API_KEY, output_format='pandas')\n",
    "\n",
    "# Get stock data\n",
    "data, metadata = ts.get_daily(symbol='AAPL', outputsize='compact')\n",
    "for d in metadata:\n",
    "    \n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aed56935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file has been created successfully.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Data to be written to the CSV file\n",
    "data = [\n",
    "    [\"Name\", \"Age\", \"City\"],\n",
    "    [\"Alice\", 30, \"New York\"],\n",
    "    [\"Bob\", 25, \"Los Angeles\"],\n",
    "    [\"Charlie\", 35, \"Chicago\"]\n",
    "]\n",
    "\n",
    "# Opening the CSV file and writing the data\n",
    "with open('people.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"CSV file has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64d76e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age         City\n",
      "0    Alice   30     New York\n",
      "1      Bob   25  Los Angeles\n",
      "2  Charlie   35      Chicago\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define the CSV file name\n",
    "filename = 'people.csv'\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "938dd821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: name 'api' is not defined\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe256672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request error: 404 Client Error: Not Found for url: https://api.marketaux.com/v1/news/?api_key=EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace 'your_api_key_here' with your actual MarketAux API key\n",
    "api_key = 'EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj'\n",
    "endpoint = 'https://api.marketaux.com/v1/news/'\n",
    "params = {\n",
    "    'api_key': api_key,\n",
    "    # Add any other required parameters according to the API documentation\n",
    "}\n",
    "\n",
    "try:\n",
    "    # Make the request to the MarketAux API\n",
    "    response = requests.get(endpoint, params=params)\n",
    "    response.raise_for_status()  # Raise an error for bad status codes\n",
    "\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    # Assuming the JSON response contains a list of headlines under 'data' key\n",
    "    for headline in data.get('data', []):\n",
    "        print(headline['title'])  # Adjust the key according to the actual response structure\n",
    "        \n",
    "#     response = requests.get(endpoint, params=params)\n",
    "#     response.raise_for_status()  # Raise an error for bad status codes\n",
    "#     soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "#     # Extract financial headlines\n",
    "#     # Note: The 'h2' and 'entry-title' class are assumptions. \n",
    "#     # Please verify and adjust according to the website's current HTML structure.\n",
    "#     headlines = soup.find_all('h2', class_='entry-title')\n",
    "    \n",
    "except requests.RequestException as e:\n",
    "    print(f\"Request error: {e}\")\n",
    "except ValueError as e:\n",
    "    print(f\"JSON decode error: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3f7331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digital Identity Solutions Provider Signicat Acquires SmartWorks\n",
      "Ontario Newsroom\n",
      "Alkhaleej Training board proposes withholding dividends for 2023\n",
      "STMicroelectronics NV at Citi TMT Conference Transcript\n",
      "CaixaBank SA Annual Shareholders Meeting Transcript\n",
      "Kijiji Scammers and General Idiots\n",
      "Securitas AB Investor Day Transcript\n",
      "Our Economy and Politics Are Broken\n",
      "Full Year 2023 Wendel SE Earnings Call Transcript\n",
      "Side hustles transforming into profitable ventures\n",
      "End of Day Message\n",
      "Word-Of-Mouth Is Still How To Get Customers\n",
      "East Pipes inks SAR 230M supply contract with SWCC\n",
      "Modern Mills to make debut on TASI on March 27\n",
      "RBL Bank aims to grow retail with new products, cut back on wholesale book\n",
      "Jefferies raises LVMH target to EUR790 on steady market share By Investing.com\n",
      "AXA SA at Morgan Stanley European Financials Conference Transcript\n",
      "Quinta Brunson To Receive Honorary Degree From Temple University\n",
      "Rising Interest Costs Squeeze Junk-Rated US Companies Amid Fed Rate Hikes\n",
      "20 Best Countries for Migration by Investment\n",
      "20 Best Countries for Migration by Investment\n",
      "Binance Labs Invests in StakeStone As It Continues to Bet Big On Restaking Sector\n",
      "Binance Labs Invests in StakeStone As It Continues to Bet Big On Restaking Sector\n",
      "Israel-US relations hit new low after US abstention at UN\n",
      "AMLO respalda el llamado de la ONU a un alto el fuego en Gaza\n",
      "5 Best Countries for Migration by Investment\n",
      "Transaction in Own Shares\n",
      "Putin says Moscow attack committed by radical Islamists\n",
      "Elon Musk Asks Why Ethereum Co-Creator Vitalik Buterin Left X\n",
      "Super Micro Stock Jumps After Bullish Call From JPMorgan\n",
      "How to improve confidence in ETFs\n",
      "OXURION announces its presence at the Paris SmallCap event on March 28, 2024.\n",
      "Netherlands fact of the day\n",
      "An 1,800-year-old Roman statue was found in a UK parking lot. How it got there is a mystery.\n",
      "Bitcoin Erupts Higher In Epic Futures Short Squeeze\n",
      "US Solar Fund ups dividend despite drop in NAV\n",
      "Deutsche Bank AG at Morgan Stanley European Financials Conference Transcript\n",
      "Q4 2023 Telia Company AB Earnings Call Transcript\n",
      "Mining scam accused Janardhan Reddy returns to BJP\n",
      "Ludwig Lachmann Biography\n",
      "15 Hungriest States in the US\n",
      "My Freighter Leases Third 767 from ATSG\n",
      "Evercore ISI maintient son opinion sur Apple avec un objectif de 220 dollars Par Investing.com\n",
      "Forgetting something\n",
      "GRWS, CEG, and HTOO are among utility movers\n",
      "Gifting expert reveals Easter chocolate might be out\n",
      "Tory Lanez Earns A New Billboard Chart Hit From Prison\n",
      "How To Unclutter Your Mind\n",
      "4E Exchange Signs Global Sponsorship Contract with Argentina National Football Team to Write a New Chapter of Sports and Finance\n",
      "Ryanair CEO Welcomes Leadership Changes At Boeing\n",
      "5 Hungriest States in the US\n",
      "Agricultural Survey\n",
      "How Athleisure Brands Like Vuori Are Harnessing NIL Influencers\n",
      "Kubicki fordert Einrichtung eines Nationalen Sicherheitsrat\n",
      "Boeing CEO to step down amid safety concerns\n",
      "Senegal election a welcome boost for coup-prone West Africa By Reuters\n",
      "How Athleisure Brands Like Vuori Are Harnessing NIL Influencers\n",
      "Kubicki fordert Einrichtung eines Nationalen Sicherheitsrat\n",
      "Boeing CEO to step down amid safety concerns\n",
      "Senegal election a welcome boost for coup-prone West Africa By Reuters\n",
      "China needs Apple even as it tries to push foreign firms out, economist says\n",
      "Elon Musk says Tesla and SpaceX are collaborating on the new Roadster\n",
      "Ericsson to lay off 1,200 staff in Sweden as 5G spending slows\n",
      "Media Finance Capital Opens New Avenues For Investors Seeking To Diversify Into Media Space\n",
      "Dow Jones Giant Verizon, Google Stock Near New Buy Points\n",
      "A New Wave of Optimism Reawakens the Bulls\n",
      "3 Wide-Moat Stocks That Could Triple By 2030\n",
      "Why HR Gets Wrongly Blamed For Management Problems\n",
      "California police asked to stop using Lego heads to disguise suspects\n",
      "LSE Opens Doors to Bitcoin and Ethereum ETN Applications\n",
      "MIS inks framework agreement with EXPRO to supply Microsoft products, services\n",
      "Giant Eagle expands DoorDash same-day delivery\n",
      "Rose Blood - A Friday The 13th Fan Film\n",
      "Friday The 13th Rose Blood - Legacy Campaign\n",
      "Reddit options launch draws bulls as shares extend gains By Reuters\n",
      "Rose Blood - The Final Campaign\n",
      "Rose Blood - The FINAL BLOOD Campaign\n",
      "Training und Wissen\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "402 Client Error: Payment Required for url: https://api.marketaux.com/v1/news/all?api_token=EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj&languages=en&page=101",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m page \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m     headlines, max_pages \u001b[38;5;241m=\u001b[39m \u001b[43mget_a_page_of_headlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m headline \u001b[38;5;129;01min\u001b[39;00m headlines:\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m filter_nicely(headline):\n",
      "Cell \u001b[0;32mIn[37], line 12\u001b[0m, in \u001b[0;36mget_a_page_of_headlines\u001b[0;34m(page)\u001b[0m\n\u001b[1;32m     10\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://api.marketaux.com/v1/news/all?\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparams\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m r \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mget(url)\n\u001b[0;32m---> 12\u001b[0m \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m json \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([x\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]], json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m/\u001b[39m json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturned\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m     http_error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1017\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Server Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreason\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for url: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1018\u001b[0m     )\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 402 Client Error: Payment Required for url: https://api.marketaux.com/v1/news/all?api_token=EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj&languages=en&page=101"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "languages = [\"en\"]\n",
    "doneglyphs = \" ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789.,-\"\n",
    "API_TOKEN = \"EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj\"\n",
    "\n",
    "def get_a_page_of_headlines(page):\n",
    "    params = urlencode({\"api_token\": API_TOKEN, \"languages\": \",\".join(languages), \"page\": page})\n",
    "    url = f\"https://api.marketaux.com/v1/news/all?{params}\"\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "    json = r.json()\n",
    "    return ([x.get(\"title\") for x in json[\"data\"]], json[\"meta\"][\"found\"] / json[\"meta\"][\"returned\"])\n",
    "\n",
    "def filter_nicely(headline):\n",
    "    # We could make exceptions for special cases here - check if we have\n",
    "    # punctuation in our supported list and drop punctuation if not, etc.\n",
    "    # But for now, the simple \"do we have all the characters in the headline?\"\n",
    "    if all((g in doneglyphs) for g in headline):\n",
    "        return headline\n",
    "\n",
    "page = 1\n",
    "while True:\n",
    "    headlines, max_pages = get_a_page_of_headlines(page)\n",
    "    for headline in headlines:\n",
    "        if filter_nicely(headline):\n",
    "            print(headline)\n",
    "    page += 1\n",
    "    if page > max_pages:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12406ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tweepy\n",
      "  Downloading tweepy-4.14.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tweepy) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests<3,>=2.27.0->tweepy) (2023.5.7)\n",
      "Downloading tweepy-4.14.0-py3-none-any.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tweepy\n",
      "Successfully installed tweepy-4.14.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0212920b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.39.2-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting filelock (from transformers)\n",
      "  Downloading filelock-3.13.3-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\n",
      "  Downloading huggingface_hub-0.22.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (1.22.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2023.12.25-cp39-cp39-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\n",
      "  Downloading tokenizers-0.15.2-cp39-cp39-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.2-cp39-cp39-macosx_10_12_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Downloading tqdm-4.66.2-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.19.3->transformers)\n",
      "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.6.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages (from requests->transformers) (2023.5.7)\n",
      "Downloading transformers-4.39.2-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.22.2-py3-none-any.whl (388 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.9/388.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.12.25-cp39-cp39-macosx_10_9_x86_64.whl (296 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.2-cp39-cp39-macosx_10_12_x86_64.whl (426 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.4/426.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.15.2-cp39-cp39-macosx_10_12_x86_64.whl (2.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.2-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.13.3-py3-none-any.whl (11 kB)\n",
      "Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, safetensors, regex, fsspec, filelock, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed filelock-3.13.3 fsspec-2024.3.1 huggingface-hub-0.22.2 regex-2023.12.25 safetensors-0.4.2 tokenizers-0.15.2 tqdm-4.66.2 transformers-4.39.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a1091a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15596\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:94: RuntimeWarning: coroutine 'main' was never awaited\n",
      "  _fun = _deprecated(_msg.format(_key))(_fun)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "C:\\Users\\15596\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "ename": "Unauthorized",
     "evalue": "401 Unauthorized\n89 - Invalid or expired token.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnauthorized\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2472\\1560532350.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;31m#     asyncio.run(main())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 96\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetch_tweets_about_sp500\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2472\\1560532350.py\u001b[0m in \u001b[0;36mfetch_tweets_about_sp500\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfetch_tweets_about_sp500\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mtweets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtwitter_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch_tweets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"S&P 500 OR SP500\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"en\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpagination_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'payload_list'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'payload_type'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpayload_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpayload_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36msearch_tweets\u001b[1;34m(self, q, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m         \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0m_Twitter\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mAPI\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mdeveloper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0men\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mapi\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0moverview\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1145\u001b[0m         \"\"\"\n\u001b[1;32m-> 1146\u001b[1;33m         return self.request(\n\u001b[0m\u001b[0;32m   1147\u001b[0m             'GET', 'search/tweets', endpoint_parameters=(\n\u001b[0;32m   1148\u001b[0m                 \u001b[1;34m'q'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'geocode'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lang'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'locale'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'result_type'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mBadRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m401\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mUnauthorized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m403\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mForbidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnauthorized\u001b[0m: 401 Unauthorized\n89 - Invalid or expired token."
     ]
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import asyncio\n",
    "import tweepy\n",
    "from transformers import pipeline\n",
    "from alpha_vantage.timeseries import TimeSeries\n",
    "from alpaca_trade_api.rest import REST as AlpacaAPI\n",
    "\n",
    "# Twitter API for sentiment analysis\n",
    "api_key = \"your_twitter_api_key\"\n",
    "api_key_secret = \"your_twitter_api_key_secret\"\n",
    "access_token = \"your_access_token\"\n",
    "access_token_secret = \"your_access_token_secret\"\n",
    "\n",
    "# Alpaca and Alpha Vantage API keys\n",
    "ALPACA_API_KEY = 'your_alpaca_api_key'\n",
    "ALPACA_SECRET_KEY = 'your_alpaca_secret_key'\n",
    "ALPACA_ENDPOINT = 'https://paper-api.alpaca.markets'\n",
    "ALPHA_VANTAGE_API_KEY = 'your_alpha_vantage_api_key'\n",
    "\n",
    "# Initialize Twitter API\n",
    "auth = tweepy.OAuthHandler(api_key, api_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "twitter_api = tweepy.API(auth)\n",
    "\n",
    "# Initialize Alpaca API\n",
    "alpaca_api = AlpacaAPI(ALPACA_API_KEY, ALPACA_SECRET_KEY, base_url=ALPACA_ENDPOINT)\n",
    "\n",
    "def fetch_tweets_about_sp500():\n",
    "    tweets = twitter_api.search_tweets(q=\"S&P 500 OR SP500\", lang=\"en\", count=100)\n",
    "    return [tweet.text for tweet in tweets]\n",
    "\n",
    "def analyze_sentiment(tweets):\n",
    "    sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "    results = sentiment_pipeline(tweets)\n",
    "    sentiment_score = sum([1 if res['label'] == 'POSITIVE' else -1 for res in results]) / len(results)\n",
    "    return sentiment_score\n",
    "\n",
    "def fetch_market_data_alpaca(symbol, start_date, end_date):\n",
    "    barset = alpaca_api.get_barset(symbol, 'day', start=start_date, end=end_date)\n",
    "    data = barset[symbol]\n",
    "    df = pd.DataFrame({\n",
    "        'time': [bar.t for bar in data],\n",
    "        'open': [bar.o for bar in data],\n",
    "        'high': [bar.h for bar in data],\n",
    "        'low': [bar.l for bar in data],\n",
    "        'close': [bar.c for bar in data],\n",
    "        'volume': [bar.v for bar in data]\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def preprocess_and_save_data(data, filename='preprocessed_data.csv'):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(data['close'].values.reshape(-1,1))\n",
    "    preprocessed_df = pd.DataFrame(scaled_data, columns=['Scaled_Close'])\n",
    "    preprocessed_df.to_csv(filename, index=False)\n",
    "    print(f\"Data saved to {filename}\")\n",
    "    return scaled_data\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def place_order(ib, action, quantity, price=None):\n",
    "    contract = Future('ES', '202406', 'GLOBEX')\n",
    "    order = MarketOrder(action, quantity) if not price else LimitOrder(action, quantity, price)\n",
    "    trade = ib.placeOrder(contract, order)\n",
    "    print(f\"Placed {action} order for {quantity} units.\")\n",
    "\n",
    "async def main():\n",
    "    ib = IB()\n",
    "    await ib.connectAsync('127.0.0.1', 7497, clientId=1)\n",
    "    \n",
    "    df = fetch_market_data_alpaca('SPY', '2023-01-01', '2023-12-31')\n",
    "    preprocessed_data = preprocess_and_save_data(df, 'market_data_preprocessed.csv')\n",
    "    \n",
    "    tweets = fetch_tweets_about_sp500()\n",
    "    sentiment_score = analyze_sentiment(tweets)\n",
    "    \n",
    "    if sentiment_score > 0:\n",
    "        place_order(ib, 'BUY', 1)  # Placeholder logic for demonstration\n",
    "    else:\n",
    "        place_order(ib, 'SELL', 1)  # Placeholder logic for demonstration\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "#     asyncio.run(main())\n",
    "    print(fetch_tweets_about_sp500())\n",
    "    print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed0c4f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           close     high    low  trade_count   open   volume  \\\n",
      "timestamp                                                                       \n",
      "2023-04-12 04:00:00+00:00  79.77  80.4800  79.49        23716  80.41  1868297   \n",
      "2023-04-13 04:00:00+00:00  79.62  79.9300  78.12        17196  79.25  3175246   \n",
      "2023-04-14 04:00:00+00:00  78.46  78.9900  78.10        25264  78.66  1676812   \n",
      "2023-04-17 04:00:00+00:00  79.14  79.4705  78.29        18519  78.81  1540053   \n",
      "2023-04-18 04:00:00+00:00  78.38  79.1500  78.04        18997  78.94  1629106   \n",
      "...                          ...      ...    ...          ...    ...      ...   \n",
      "2024-04-05 04:00:00+00:00  58.51  58.8488  58.06        20408  58.55  1426325   \n",
      "2024-04-08 04:00:00+00:00  59.47  59.6100  58.58        22551  58.58  1654333   \n",
      "2024-04-09 04:00:00+00:00  59.96  60.4400  59.43        25039  59.57  1862118   \n",
      "2024-04-10 04:00:00+00:00  59.07  59.3900  58.28        31914  59.24  2344801   \n",
      "2024-04-11 04:00:00+00:00  59.15  59.6600  58.54        19995  59.49  1310097   \n",
      "\n",
      "                                vwap  \n",
      "timestamp                             \n",
      "2023-04-12 04:00:00+00:00  79.918205  \n",
      "2023-04-13 04:00:00+00:00  79.245168  \n",
      "2023-04-14 04:00:00+00:00  78.538565  \n",
      "2023-04-17 04:00:00+00:00  79.036700  \n",
      "2023-04-18 04:00:00+00:00  78.398365  \n",
      "...                              ...  \n",
      "2024-04-05 04:00:00+00:00  58.445746  \n",
      "2024-04-08 04:00:00+00:00  59.393755  \n",
      "2024-04-09 04:00:00+00:00  59.873256  \n",
      "2024-04-10 04:00:00+00:00  58.858833  \n",
      "2024-04-11 04:00:00+00:00  59.059843  \n",
      "\n",
      "[252 rows x 7 columns]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import tweepy\n",
    "from transformers import pipeline\n",
    "from alpaca_trade_api.rest import REST, TimeFrame\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "# Calculate the start and end dates for the last 5 days\n",
    "end_date = datetime.today() - timedelta(days=1)  # Fetch data until yesterday\n",
    "start_date = end_date - timedelta(days=365)  # Fetch data from 5 days ago\n",
    "\n",
    "# Format dates in ISO 8601 format (YYYY-MM-DD)\n",
    "start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "# Initialize Alpaca API\n",
    "ALPACA_API_KEY = 'PKHIU3GSGREXWZOJSIP2'\n",
    "ALPACA_SECRET_KEY = 'Gi1lOxqYrvvLb3PMNEMEnqa4b0IRTbG73GZEbWVf'\n",
    "alpaca_api = REST(ALPACA_API_KEY, ALPACA_SECRET_KEY, base_url='https://paper-api.alpaca.markets')\n",
    "\n",
    "# Initialize Twitter API\n",
    "auth = tweepy.OAuthHandler(\"FOzAGryMn6KTGhZ4oCPXZrwDw\", \"D9EUFQU5x9yk47UVPipGltuokzVeE3JZ9fScogcNmwHaRgrOwF\")\n",
    "auth.set_access_token(\"1773744788291960837-2eaPvcMt0ADfRsxSMNy77QN4kjb874\", \"uiPMWeX1UVOa7qRYylvaRXaEqRQ8qIgQgBjvkSLGdleim\")\n",
    "twitter_api = tweepy.API(auth)\n",
    "\n",
    "# Initialize Transformers Pipeline for Sentiment Analysis\n",
    "\n",
    "# sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "def fetch_market_data(symbol, start_date, end_date):\n",
    "    data = alpaca_api.get_bars(symbol, TimeFrame.Day, start_date, end_date).df\n",
    "    return data\n",
    "\n",
    "# def fetch_tweets_about_sp500(count=1):\n",
    "#     tweets = twitter_api.search_tweets(q=\"S&P 500 OR SP500\", lang=\"en\", result_type=\"recent\", count=count)\n",
    "#     return [tweet.text for tweet in tweets]\n",
    "\n",
    "def analyze_sentiment(tweets):\n",
    "    results = sentiment_pipeline(tweets)\n",
    "    scores = [1 if res['label'] == 'POSITIVE' else -1 for res in results]\n",
    "    return np.mean(scores)\n",
    "\n",
    "def preprocess_data(market_data, sentiment_score):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_data = scaler.fit_transform(market_data.values.reshape(-1, 1))\n",
    "    # Include sentiment score as a feature\n",
    "    features = np.hstack((scaled_data, np.full((scaled_data.shape[0], 1), fill_value=sentiment_score)))\n",
    "    return features[:-1], scaled_data[1:]  # X, y for model training\n",
    "\n",
    "def preprocess_for_lstm(market_data, sentiments):\n",
    "    # Assuming market_data is a DataFrame with a 'close' column\n",
    "    # and sentiments is a list of sentiment scores (-1 for negative, 0 for neutral, 1 for positive)\n",
    "    market_data['sentiment'] = sentiments[:len(market_data)]  # Truncate or pad sentiments to match market_data length\n",
    "    features = market_data[['close', 'sentiment']].values\n",
    "    return features\n",
    "\n",
    "def create_lstm_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "def analyze_sentiment_with_bert(news):\n",
    "    sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
    "    return sentiment_pipeline(news)\n",
    "\n",
    "def preprocess_and_save_data(data, filename):\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     scaled_data = scaler.fit_transform(data.values.reshape(-1,1))\n",
    "#     preprocessed_df = pd.DataFrame(scaled_data, columns=['Timestamp', 'Close','High','Low','Trade_count','Open', 'Volume',' Volume Weighted Average Price'])\n",
    "#     preprocessed_df.to_csv(filename, index=False)\n",
    "#     print(f\"Data saved to {filename}\")\n",
    "#     return scaled_data\n",
    "    data.to_csv(filename, index=False)\n",
    "#     return scaled_data\n",
    "\n",
    "def main():\n",
    "    print(fetch_market_data('ES', start_date_str, end_date_str))\n",
    "    market_data = fetch_market_data('ES', start_date_str, end_date_str)\n",
    "#     tweets = fetch_tweets_about_sp500()\n",
    "#     sentiment_score = analyze_sentiment(tweets)\n",
    "#     X, y = preprocess_data(market_data, sentiment_score)\n",
    "    \n",
    "#     model = create_lstm_model((X.shape[1], X.shape[2]))\n",
    "#     model.fit(X, y, epochs=10, batch_size=32)\n",
    "\n",
    "    print(preprocess_and_save_data(market_data, 'es500_price_history.csv'))\n",
    "\n",
    "    # Simplified decision making based on the last day's prediction\n",
    "#     last_sequence = X[-1].reshape(1, X.shape[1], X.shape[2])\n",
    "#     predicted_change = model.predict(last_sequence)\n",
    "#     decision = \"BUY\" if predicted_change > 0 else \"SELL\"\n",
    "#     print(f\"Trading decision based on model prediction: {decision}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dbb0ca61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15596\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.1236 - val_loss: 0.0269\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0218 - val_loss: 0.0299\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0199 - val_loss: 0.0204\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0137 - val_loss: 0.0228\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0110 - val_loss: 0.0168\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0080 - val_loss: 0.0151\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - val_loss: 0.0133\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0069 - val_loss: 0.0133\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0080 - val_loss: 0.0123\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - val_loss: 0.0110\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - val_loss: 0.0106\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - val_loss: 0.0107\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0066 - val_loss: 0.0104\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - val_loss: 0.0101\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0066 - val_loss: 0.0107\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - val_loss: 0.0100\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0059 - val_loss: 0.0099\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0052 - val_loss: 0.0095\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0052 - val_loss: 0.0090\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - val_loss: 0.0086\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0049 - val_loss: 0.0084\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0050 - val_loss: 0.0084\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0083\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0051 - val_loss: 0.0080\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0081\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0055 - val_loss: 0.0080\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0050 - val_loss: 0.0081\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0051 - val_loss: 0.0074\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0046 - val_loss: 0.0074\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0049 - val_loss: 0.0071\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0049 - val_loss: 0.0067\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0037 - val_loss: 0.0061\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0064\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0040 - val_loss: 0.0071\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0042 - val_loss: 0.0063\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0040 - val_loss: 0.0060\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0039 - val_loss: 0.0056\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0051 - val_loss: 0.0056\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0035 - val_loss: 0.0058\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0040 - val_loss: 0.0056\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0039 - val_loss: 0.0052\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0039 - val_loss: 0.0053\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0035 - val_loss: 0.0043\n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0034 - val_loss: 0.0040\n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0032 - val_loss: 0.0040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 168ms/step\n",
      "Trading decision: BUY\n"
     ]
    }
   ],
   "source": [
    "#use only LSTM model and past past history to predict price and make trading decision\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Step 1: Load and preprocess the data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    close_prices = data['close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_close_prices = scaler.fit_transform(close_prices)\n",
    "    return scaled_close_prices, scaler\n",
    "\n",
    "# Create sequences from the data\n",
    "def create_sequences(data, sequence_length=60):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        x = data[i:(i + sequence_length)]\n",
    "        y = data[i + sequence_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Step 2: Define the LSTM model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(units=50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(units=50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=25),\n",
    "        Dense(units=1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Step 3: Train the model\n",
    "def train_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Step 4: Make a trading decision\n",
    "def make_trading_decision(model, latest_sequence_scaled, scaler):\n",
    "    predicted_price_scaled = model.predict(latest_sequence_scaled[np.newaxis, :, :])\n",
    "    predicted_price = scaler.inverse_transform(predicted_price_scaled)[0, 0]\n",
    "    latest_known_price = scaler.inverse_transform(latest_sequence_scaled[-1].reshape(-1, 1))[0, 0]\n",
    "    \n",
    "    if predicted_price > latest_known_price:\n",
    "        decision = \"BUY\"\n",
    "    elif predicted_price < latest_known_price:\n",
    "        decision = \"SELL\"\n",
    "    else:\n",
    "        decision = \"HOLD\"\n",
    "    \n",
    "    return decision\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = 'es500_price_history.csv'  # Replace this with the path to your CSV file\n",
    "    scaled_close_prices, scaler = load_and_preprocess_data(filepath)\n",
    "    X, y = create_sequences(scaled_close_prices)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = build_model((X_train.shape[1], 1))\n",
    "    train_model(model, X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Example: Making a trading decision based on the latest sequence of prices\n",
    "    latest_sequence_scaled = X_test[-1]  # Assuming this is the latest available sequence\n",
    "    decision = make_trading_decision(model, latest_sequence_scaled, scaler)\n",
    "    print(f\"Trading decision: {decision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e8ede67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15596\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.0936 - val_loss: 0.0115\n",
      "Epoch 2/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0202 - val_loss: 0.0107\n",
      "Epoch 3/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0120 - val_loss: 0.0145\n",
      "Epoch 4/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0128 - val_loss: 0.0125\n",
      "Epoch 5/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0112 - val_loss: 0.0068\n",
      "Epoch 6/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0085 - val_loss: 0.0061\n",
      "Epoch 7/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0082 - val_loss: 0.0081\n",
      "Epoch 8/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 9/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0067 - val_loss: 0.0054\n",
      "Epoch 10/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 11/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0076 - val_loss: 0.0074\n",
      "Epoch 12/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - val_loss: 0.0047\n",
      "Epoch 13/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 14/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0052 - val_loss: 0.0062\n",
      "Epoch 15/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0062 - val_loss: 0.0056\n",
      "Epoch 16/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0071 - val_loss: 0.0037\n",
      "Epoch 17/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 18/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 19/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 20/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 21/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0050 - val_loss: 0.0064\n",
      "Epoch 22/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 23/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 24/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 25/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 26/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 27/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 28/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 29/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 30/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 31/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 32/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 33/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 34/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 35/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 36/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 37/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 38/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 39/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 40/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 41/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 42/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 43/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 44/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 45/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 46/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 47/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 48/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 49/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 50/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 51/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - val_loss: 0.0030\n",
      "Epoch 52/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 53/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 54/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 55/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 56/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 57/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 58/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0041 - val_loss: 0.0034\n",
      "Epoch 59/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 60/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 61/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 62/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 63/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 64/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 65/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 66/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 67/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 68/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 69/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 71/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 72/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 73/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 74/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 75/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 76/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 77/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 78/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 79/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 80/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 81/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 82/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 83/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 84/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 85/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 86/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 87/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 88/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 89/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 90/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 91/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 92/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 93/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 94/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 95/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 96/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 97/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 98/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 99/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 100/100\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0031 - val_loss: 0.0021\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 162ms/step\n",
      "Decision based on current price 78.05: SELL\n"
     ]
    }
   ],
   "source": [
    "#use only LSTM model and past past history to predict price and make trading decision, with decision to hold added\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    close_prices = data['close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_close_prices = scaler.fit_transform(close_prices)\n",
    "    return scaled_close_prices, scaler\n",
    "\n",
    "# Create sequences\n",
    "def create_sequences(data, sequence_length=60):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data)-sequence_length):\n",
    "        x = data[i:(i+sequence_length)]\n",
    "        y = data[i+sequence_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Define LSTM model\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(25),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Predict and decide\n",
    "def predict_and_decide(current_price, recent_prices, model, scaler):\n",
    "#     recent_prices = np.append(recent_prices, current_price).reshape(-1, 1)\n",
    "#     scaled_recent_prices = scaler.transform(recent_prices)\n",
    "    \n",
    "#     # Adjust for the sequence length expected by the model\n",
    "#     if len(scaled_recent_prices) > 60:\n",
    "#         scaled_recent_prices = scaled_recent_prices[-60:]\n",
    "#     elif len(scaled_recent_prices) < 60:\n",
    "#         scaled_recent_prices = np.pad(scaled_recent_prices, (60-len(scaled_recent_prices), 0), 'constant', constant_values=(0))\n",
    "    \n",
    "#     predicted_price_scaled = model.predict(scaled_recent_prices.T[np.newaxis, :, :])\n",
    "#     predicted_price = scaler.inverse_transform(predicted_price_scaled)[0, 0]\n",
    "    \n",
    "#     decision = \"BUY\" if predicted_price > current_price else \"SELL\" if predicted_price < current_price else \"HOLD\"\n",
    "#     return decision\n",
    "\n",
    "    # Ensure recent_prices includes the current_price and has the correct shape\n",
    "    recent_prices = np.append(recent_prices[-59:], current_price).reshape(-1, 1)\n",
    "    scaled_recent_prices = scaler.transform(recent_prices)\n",
    "    \n",
    "    # Reshape for the model: (1, sequence_length, 1)\n",
    "    scaled_recent_prices = scaled_recent_prices.reshape(1, -1, 1)\n",
    "    \n",
    "    # Predict the next day's price\n",
    "    predicted_price_scaled = model.predict(scaled_recent_prices)\n",
    "    predicted_price = scaler.inverse_transform(predicted_price_scaled)[0, 0]\n",
    "    \n",
    "    # Make a decision\n",
    "    decision = \"BUY\" if predicted_price > current_price else \"SELL\" if predicted_price < current_price else \"HOLD\"\n",
    "    return decision\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    filepath = 'es500_price_history.csv'  # Update with the path to your data\n",
    "    scaled_close_prices, scaler = load_and_preprocess_data(filepath)\n",
    "    X, y = create_sequences(scaled_close_prices)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Build and train model\n",
    "    model = build_model((X_train.shape[1], 1))\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "    \n",
    "    # Assuming you have a list/array of recent prices and the current price\n",
    "    recent_prices = scaled_close_prices[-59:]  # Get the last 59 prices\n",
    "    current_price = 78.05  # This would be dynamically obtained in a real scenario\n",
    "    \n",
    "    # Make decision\n",
    "    decision = predict_and_decide(current_price, recent_prices, model, scaler)\n",
    "    print(f\"Decision based on current price {current_price}: {decision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6fdc889",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import alpaca_trade_api as tradeapi\n",
    "\n",
    "# Set your API key and secret\n",
    "API_KEY = 'PKHIU3GSGREXWZOJSIP2'\n",
    "API_SECRET = 'Gi1lOxqYrvvLb3PMNEMEnqa4b0IRTbG73GZEbWVf'\n",
    "BASE_URL = 'https://paper-api.alpaca.markets'  # or 'https://api.alpaca.markets' for live trading\n",
    "\n",
    "# Initialize the API connection\n",
    "api = tradeapi.REST(API_KEY, API_SECRET, base_url=BASE_URL, api_version='v2')\n",
    "\n",
    "# Get stock data\n",
    "barset = api.get_bars('MES', '1D', limit=1)\n",
    "# aapl_bars = barset['ES']\n",
    "for bar in barset:\n",
    "    print(bar.t, bar.o, bar.h, bar.l, bar.c, bar.v)\n",
    "    current_price = bar.c\n",
    "    print(\"close price\", bar.c)\n",
    "    \n",
    "# decision = predict_and_decide(current_price, recent_prices, model, scaler)\n",
    "# print(f\"Decision based on current price {current_price}: {decision}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe38cb9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5434912",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "404 Client Error: Not Found for url: https://api.marketaux.com/v1/sentiment?api_token=EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj&languages=en&query=S%26P+500",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2472\\1634221967.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Fetch and print the sentiment score for S&P 500-related news\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0msp500_sentiment_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_sp500_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"S&P 500 Sentiment Score: {sp500_sentiment_score}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2472\\1634221967.py\u001b[0m in \u001b[0;36mget_sp500_sentiment\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"https://api.marketaux.com/v1/sentiment?{urlencode(params)}\"\u001b[0m  \u001b[1;31m# Hypothetical endpoint for sentiment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mjson_response\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\requests\\models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1019\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1020\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1021\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1022\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.marketaux.com/v1/sentiment?api_token=EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj&languages=en&query=S%26P+500"
     ]
    }
   ],
   "source": [
    "#sentiment analysis using fetched marketaux headline\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "API_TOKEN = \"EQIIjldXyt4Jyk9qre8RAdnbXzVyumxGguFnV7Rj\"\n",
    "languages = [\"en\"]\n",
    "\n",
    "def get_sp500_sentiment():\n",
    "    params = {\n",
    "        \"api_token\": API_TOKEN,\n",
    "        \"languages\": \",\".join(languages),\n",
    "        \"query\": \"S&P 500\",  # Assuming 'query' parameter can be used to filter news by keywords\n",
    "    }\n",
    "    url = f\"https://api.marketaux.com/v1/sentiment?{urlencode(params)}\"  # Hypothetical endpoint for sentiment\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    json_response = response.json()\n",
    "    \n",
    "    # Assuming the API response contains a sentiment score for the query\n",
    "    sentiment_score = json_response.get(\"sentiment_score\")\n",
    "    return sentiment_score\n",
    "\n",
    "# Fetch and print the sentiment score for S&P 500-related news\n",
    "sp500_sentiment_score = get_sp500_sentiment()\n",
    "print(f\"S&P 500 Sentiment Score: {sp500_sentiment_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "03b1f6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account Balance: 1047515.017\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "Decision: SELL | Shares: 50 | Current Profit: $202.50\n"
     ]
    }
   ],
   "source": [
    "from ib_insync import *\n",
    "\n",
    "# Assuming 'ib' is already connected and is an instance of ib_insync.IB()\n",
    "\n",
    "# Use the asynchronous version of the accountSummary function with await\n",
    "account_summary = await ib.accountSummaryAsync()\n",
    "\n",
    "# Find the total cash balance\n",
    "balance = next((item for item in account_summary if item.tag == 'TotalCashBalance'), None)\n",
    "print(\"Account Balance:\", balance.value if balance else \"No balance found\")\n",
    "available_funds = balance.value\n",
    "decision, current_profit = predict_and_decide(current_price, recent_prices, model, scaler, available_funds, current_shares, total_cost)\n",
    "print(f\"Decision: {decision[0]} | Shares: {decision[1]} | Current Profit: ${current_profit:.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11695a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contract: ESM4 | Shares: -4.0 | Avg Cost: 265410.25\n"
     ]
    }
   ],
   "source": [
    "def fetch_positions():\n",
    "    positions = ib.positions()\n",
    "    for pos in positions:\n",
    "        if pos.contract.symbol == 'ES' and pos.contract.secType == 'FUT':\n",
    "            print(f\"Contract: {pos.contract.localSymbol} | Shares: {pos.position} | Avg Cost: {pos.avgCost}\")\n",
    "\n",
    "# Fetch and print ES positions\n",
    "fetch_positions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6cc46f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in c:\\users\\15596\\anaconda3\\lib\\site-packages (1.5.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de6e4b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Price of ES: Last - 5084.0, Bid - 5083.75, Ask - 5084.0\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def fetch_current_price(ib, contract):\n",
    "    # Request market data snapshot for the contract\n",
    "    market_data = ib.reqMktData(contract, '', False, False)\n",
    "#     ib.sleep(2)  # Wait for the data to be returned\n",
    "    util.sleep(5)\n",
    "    if market_data:\n",
    "        print(f\"Current Price of {contract.symbol}: Last - {market_data.last}, Bid - {market_data.bid}, Ask - {market_data.ask}\")\n",
    "    else:\n",
    "        print(\"Failed to fetch current price.\")\n",
    "contract = Future('ES', '202406', 'CME')\n",
    "fetch_current_price(ib, contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0714a829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15596\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - loss: 0.3589 - val_loss: 0.0430\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0507 - val_loss: 0.0788\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0645 - val_loss: 0.0156\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0254 - val_loss: 0.0223\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0303 - val_loss: 0.0211\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0279 - val_loss: 0.0122\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0165 - val_loss: 0.0177\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0217 - val_loss: 0.0159\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0168 - val_loss: 0.0105\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0144 - val_loss: 0.0101\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0173 - val_loss: 0.0091\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0159 - val_loss: 0.0094\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0172 - val_loss: 0.0091\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0135 - val_loss: 0.0078\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0143 - val_loss: 0.0074\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0144 - val_loss: 0.0072\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0138 - val_loss: 0.0071\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0105 - val_loss: 0.0069\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0112 - val_loss: 0.0067\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0118 - val_loss: 0.0066\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0111 - val_loss: 0.0065\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0104 - val_loss: 0.0065\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0112 - val_loss: 0.0064\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0108 - val_loss: 0.0064\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0104 - val_loss: 0.0063\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0118 - val_loss: 0.0067\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0135 - val_loss: 0.0063\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0116 - val_loss: 0.0065\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0110 - val_loss: 0.0067\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0097 - val_loss: 0.0062\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0119 - val_loss: 0.0063\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0111 - val_loss: 0.0062\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0110 - val_loss: 0.0062\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0135 - val_loss: 0.0060\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0118 - val_loss: 0.0059\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0098 - val_loss: 0.0060\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0130 - val_loss: 0.0061\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0095 - val_loss: 0.0060\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0107 - val_loss: 0.0060\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0107 - val_loss: 0.0059\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0097 - val_loss: 0.0061\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0125 - val_loss: 0.0066\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0104 - val_loss: 0.0059\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0089 - val_loss: 0.0061\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0100 - val_loss: 0.0058\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0088 - val_loss: 0.0057\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0113 - val_loss: 0.0057\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0106 - val_loss: 0.0057\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0120 - val_loss: 0.0058\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0109 - val_loss: 0.0056\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0137 - val_loss: 0.0056\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0103 - val_loss: 0.0056\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0085 - val_loss: 0.0056\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0115 - val_loss: 0.0056\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0092 - val_loss: 0.0055\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0100 - val_loss: 0.0054\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0089 - val_loss: 0.0056\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0104 - val_loss: 0.0060\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0113 - val_loss: 0.0054\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0118 - val_loss: 0.0055\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0080 - val_loss: 0.0054\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0109 - val_loss: 0.0053\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0111 - val_loss: 0.0053\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0097 - val_loss: 0.0053\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0086 - val_loss: 0.0054\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0099 - val_loss: 0.0054\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0115 - val_loss: 0.0052\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0084 - val_loss: 0.0054\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0104 - val_loss: 0.0053\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0105 - val_loss: 0.0052\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0101 - val_loss: 0.0051\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0091 - val_loss: 0.0051\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0119 - val_loss: 0.0054\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0097 - val_loss: 0.0057\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0103 - val_loss: 0.0053\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0107 - val_loss: 0.0053\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0079 - val_loss: 0.0053\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0128 - val_loss: 0.0052\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0081 - val_loss: 0.0051\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0098 - val_loss: 0.0051\n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0096 - val_loss: 0.0050\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0090 - val_loss: 0.0051\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0094 - val_loss: 0.0051\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0084 - val_loss: 0.0050\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0110 - val_loss: 0.0053\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0086 - val_loss: 0.0049\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0094 - val_loss: 0.0057\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0091 - val_loss: 0.0049\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0082 - val_loss: 0.0049\n",
      "5068.625 [[0.35855004]\n",
      " [0.29472025]\n",
      " [0.32702916]\n",
      " [0.24507486]\n",
      " [0.08747045]\n",
      " [0.09377463]\n",
      " [0.15287628]\n",
      " [0.20094563]\n",
      " [0.25689519]] <Sequential name=sequential_11, built=True> MinMaxScaler() 1075145.4027 10.0 50686.25\n",
      "[[[-15.76482727]\n",
      "  [-15.76502846]\n",
      "  [-15.76492662]\n",
      "  [-15.76518495]\n",
      "  [-15.76568173]\n",
      "  [-15.76566186]\n",
      "  [-15.76547557]\n",
      "  [-15.76532405]\n",
      "  [-15.76514769]\n",
      "  [  0.2107959 ]]]\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 161ms/step\n",
      "4404.6797 5068.625\n",
      "6639.453125\n",
      "Decision: SELL | Shares: 1 | Current Profit: $0.00\n"
     ]
    }
   ],
   "source": [
    "#Model updated to learn from the data from IB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    close_prices = data['close'].values.reshape(-1, 1)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_close_prices = scaler.fit_transform(close_prices)\n",
    "    return scaled_close_prices, scaler\n",
    "\n",
    "# Create sequences for LSTM training\n",
    "def create_sequences(data, sequence_length=60):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        x = data[i:(i + sequence_length)]\n",
    "        y = data[i + sequence_length]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Define LSTM model structure\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50, return_sequences=False),\n",
    "        Dropout(0.2),\n",
    "        Dense(25),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Predict next day's price and make a decision\n",
    "def predict_and_decide(current_price, recent_prices, model, scaler, available_funds, current_shares, total_cost, transaction_fee=10.0):\n",
    "    recent_prices = np.append(recent_prices[-59:], current_price).reshape(-1, 1)\n",
    "#     print(recent_prices)\n",
    "    scaled_recent_prices = scaler.transform(recent_prices)\n",
    "    scaled_recent_prices = scaled_recent_prices.reshape(1, -1, 1)\n",
    "    print(scaled_recent_prices)\n",
    "    \n",
    "    predicted_price_scaled = model.predict(scaled_recent_prices)\n",
    "    predicted_price = scaler.inverse_transform(predicted_price_scaled)[0, 0]\n",
    "    print(predicted_price,current_price)\n",
    "    \n",
    "    # Decision making with transaction fees considered\n",
    "    if predicted_price > current_price:\n",
    "        potential_profit = (predicted_price - current_price) * current_shares\n",
    "        print(potential_profit)\n",
    "        if available_funds > transaction_fee and potential_profit > 0:\n",
    "            # Calculate optimal number of shares to buy based on potential profit and available funds\n",
    "            # Here we assume a strategy to use a fraction of available funds\n",
    "            funds_for_use = available_funds * 0.1 - transaction_fee  # Example: using 10% of available funds\n",
    "            max_affordable_shares = int(funds_for_use / current_price)\n",
    "            decision = \"BUY\", max_affordable_shares\n",
    "        else:\n",
    "            decision = \"HOLD\", 0\n",
    "    elif predicted_price < current_price:\n",
    "        potential_loss = (current_price - predicted_price) * current_shares\n",
    "        print(potential_loss)\n",
    "        if potential_loss > 0:\n",
    "            # Sell a fraction of shares to minimize potential loss\n",
    "            shares_to_sell = int(current_shares * 0.1)  # Example: selling 10% of holdings\n",
    "            decision = \"SELL\", shares_to_sell\n",
    "        else:\n",
    "            decision = \"HOLD\", 0\n",
    "    else:\n",
    "        decision = \"HOLD\", 0\n",
    "    \n",
    "    current_profit = (current_price * current_shares) - total_cost\n",
    "    return decision, current_profit\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = 'ib_es500_price_history.csv'  # Updated filepath to the uploaded CSV\n",
    "    scaled_close_prices, scaler = load_and_preprocess_data(filepath)\n",
    "    X, y = create_sequences(scaled_close_prices)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = build_model((X_train.shape[1], 1))\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n",
    "    \n",
    "    positions = ib.positions()\n",
    "    for pos in positions:\n",
    "        if pos.contract.symbol == 'ES' and pos.contract.secType == 'FUT':\n",
    "            current_shares = pos.position\n",
    "    account_summary = await ib.accountSummaryAsync()\n",
    "\n",
    "    # Find the total cash balance\n",
    "    balance = next((item for item in account_summary if item.tag == 'TotalCashBalance'), None)\n",
    "    \n",
    "    contract = Future('ES', '202406', 'CME')\n",
    "    market_data = ib.reqMktData(contract, '', False, False)\n",
    "    util.sleep(5)\n",
    "    current_price = (market_data.bid + market_data.ask) / 2\n",
    "\n",
    "    \n",
    "    available_funds = balance.value\n",
    "    recent_prices = scaled_close_prices[-60:-1]  # Using the last 59 prices for prediction\n",
    "    total_cost = current_shares * current_price  # Adjusted total cost calculation\n",
    "    print(current_price, recent_prices, model, scaler, available_funds, current_shares, total_cost)\n",
    "    \n",
    "    decision, current_profit = predict_and_decide(current_price, recent_prices, model, scaler, available_funds, current_shares, total_cost)\n",
    "    print(f\"Decision: {decision[0]} | Shares: {decision[1]} | Current Profit: ${current_profit:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9736f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Load and preprocess data\n",
    "def load_and_preprocess_data(filepath):\n",
    "    data = pd.read_csv(filepath)\n",
    "    # Adding more features: high, low, and volume\n",
    "    features = data[['close', 'high', 'low', 'volume']].values\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_features = scaler.fit_transform(features)\n",
    "    return scaled_features, scaler\n",
    "\n",
    "# Create sequences for LSTM training\n",
    "def create_sequences(data, sequence_length=60):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - sequence_length):\n",
    "        x = data[i:(i + sequence_length)]\n",
    "        y = data[i + sequence_length, 0]  # Predicting the next close price\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "# Define LSTM model structure\n",
    "def build_model(input_shape):\n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(50),\n",
    "        Dropout(0.2),\n",
    "        Dense(25),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model\n",
    "\n",
    "# Adjust the prediction function to handle new features\n",
    "def predict_and_decide(model, scaler, recent_data, current_price, available_funds, current_shares, total_cost, transaction_fee=10.0):\n",
    "#     if recent_data.shape[0] != 60:\n",
    "#         raise ValueError(\"recent_data should contain exactly 60 timesteps\")\n",
    "    \n",
    "#     # Scale the recent_data if it's not already scaled\n",
    "#     scaled_recent_data = scaler.transform(recent_data)\n",
    "#     scaled_recent_data = scaled_recent_data.reshape(1, 60, -1)  # Reshape for LSTM input\n",
    "#     prediction = model.predict(scaled_recent_data)\n",
    "#     predicted_price = scaler.inverse_transform(prediction)[0][0]\n",
    "    # Assuming recent_data is in the correct shape and already scaled appropriately\n",
    "    scaled_recent_data = recent_data.reshape(1, 60, -1)  # Reshape for LSTM input\n",
    "    \n",
    "    prediction_scaled = model.predict(scaled_recent_data)\n",
    "    \n",
    "    # Since we're only interested in the 'close' price (first feature), we need to prepare a dummy array for inverse transform\n",
    "    dummy_features = np.zeros((1, 4))  # Assume 4 features as per your scaler fitting\n",
    "    dummy_features[0, 0] = prediction_scaled[0][0]  # Place the predicted price in the 'close' position\n",
    "    \n",
    "    predicted_price = scaler.inverse_transform(dummy_features)[0, 0]  # Inverse transform and extract the 'close' price\n",
    "    print(predicted_price, current_price)\n",
    "    # Decision making with transaction fees considered\n",
    "    decision = \"HOLD\"\n",
    "    shares = 0\n",
    "    if predicted_price > current_price:\n",
    "        if available_funds > transaction_fee:\n",
    "            max_affordable_shares = int((available_funds - transaction_fee) / current_price)\n",
    "            decision = \"BUY\"\n",
    "            shares = max_affordable_shares  # Example: Buy as much as possible within budget\n",
    "    elif predicted_price < current_price:\n",
    "        decision = \"SELL\"\n",
    "        shares = int(current_shares * 0.1)  # Example: Sell 10% of holdings\n",
    "    \n",
    "    return decision, shares, predicted_price\n",
    "\n",
    "# Example usage of the functions\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = 'ib_es500_price_history.csv'\n",
    "    scaled_features, scaler = load_and_preprocess_data(filepath)\n",
    "    X, y = create_sequences(scaled_features)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = build_model((X_train.shape[1], X_train.shape[2]))\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test))  # Reduced epochs, added explicit test data for validation\n",
    "    \n",
    "\n",
    "    # Simulating a scenario for prediction and decision making\n",
    "    positions = ib.positions()\n",
    "    for pos in positions:\n",
    "        if pos.contract.symbol == 'ES' and pos.contract.secType == 'FUT':\n",
    "            current_shares = pos.position\n",
    "    account_summary = await ib.accountSummaryAsync()\n",
    "    # Find the total cash balance\n",
    "    balance = next((item for item in account_summary if item.tag == 'TotalCashBalance'), None)\n",
    "    \n",
    "    contract = Future('ES', '202406', 'CME')\n",
    "    market_data = ib.reqMktData(contract, '', False, False)\n",
    "    util.sleep(5)\n",
    "    current_price = (market_data.bid + market_data.ask) / 2\n",
    "\n",
    "    \n",
    "    available_funds = balance.value\n",
    "    total_cost = current_shares * current_price  # Simulated total cost of current shares\n",
    "    \n",
    "    # Prepare recent data for prediction\n",
    "    recent_data = scaled_features[-60:]  # Make sure this is exactly 60 timesteps\n",
    "    decision, shares, predicted_price = predict_and_decide(model, scaler, recent_data, current_price, available_funds, current_shares, total_cost)\n",
    "    print(f\"Decision: {decision}, Shares: {shares}, Predicted Price: {predicted_price}\")\n",
    "    \n",
    "    # Execute the decision\n",
    "    if decision == \"BUY\":\n",
    "        order = MarketOrder('BUY', shares)\n",
    "        trade = ib.placeOrder(contract, order)\n",
    "    elif decision == \"SELL\":\n",
    "        order = MarketOrder('SELL', shares)\n",
    "        trade = ib.placeOrder(contract, order)\n",
    "    elif decision == \"HOLD\":\n",
    "        print(\"Decision is to HOLD, no action taken.\")\n",
    "\n",
    "    # Monitor the order until it is filled\n",
    "    ib.sleep(1)  # Sleeping to give time for the order to be executed\n",
    "\n",
    "\n",
    "    print(f\"Order {decision} for {shares} shares has been filled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852a89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_funds = 10000\n",
    "current_price = 5012\n",
    "recent_prices = scaled_close_prices[-60:-1]\n",
    "current_shares = 50\n",
    "total_cost = current_shares*current_price\n",
    "decision, current_profit = predict_and_decide(current_price, recent_prices, model, scaler, available_funds, current_shares, total_cost)\n",
    "print(f\"Decision: {decision[0]} | Shares: {decision[1]} | Current Profit: ${current_profit:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ac66def",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096753.8012\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# Assuming these classes and instances are defined elsewhere in your code\n",
    "class Order:\n",
    "    def __init__(self, action, totalQuantity, orderType, lmtPrice):\n",
    "        self.action = action\n",
    "        self.totalQuantity = totalQuantity\n",
    "        self.orderType = orderType\n",
    "        self.lmtPrice = lmtPrice\n",
    "\n",
    "# Placeholder for the 'contract' and 'ib' instances\n",
    "# contract = None  # You should define this properly\n",
    "# ib = None  # Initialize this with your brokerage interface instance\n",
    "\n",
    "async def buy(tq, ot, lp):\n",
    "    order = Order(action='BUY', totalQuantity=tq, orderType=ot, lmtPrice=lp)\n",
    "    trade = await ib.placeOrder(contract, order)\n",
    "\n",
    "async def sell(tq, ot, lp):\n",
    "    order = Order(action='SELL', totalQuantity=tq, orderType=ot, lmtPrice=lp)\n",
    "    trade = await ib.placeOrder(contract, order)\n",
    "\n",
    "async def check_total_cash_balance():\n",
    "    try:\n",
    "        account_summary = await ib.accountSummaryAsync()\n",
    "        balance = next((item for item in account_summary if item.tag == 'TotalCashBalance'), None)\n",
    "        return balance.value  # Assuming 'balance' has a 'value' attribute.\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {e}\"\n",
    "\n",
    "async def main():\n",
    "    balance = await check_total_cash_balance()\n",
    "    print(balance)\n",
    "\n",
    "# Adjusted way to run the main function in environments with an existing event loop\n",
    "if __name__ == \"__main__\":\n",
    "    loop = asyncio.get_event_loop()\n",
    "    if loop.is_running():\n",
    "        # In environments like Jupyter, directly schedule the coroutine to be run\n",
    "        task = loop.create_task(main())\n",
    "    else:\n",
    "        # In standard environments without a running loop, use asyncio.run()\n",
    "        asyncio.run(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72329b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
